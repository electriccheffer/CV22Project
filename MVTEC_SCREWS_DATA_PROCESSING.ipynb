{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Documents\\schoolwork-files\\archive\\PhD_Research\\2022\\ComputerVision\\screws_project\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objects 4427\n",
      "Categories 13\n",
      "Images 384\n"
     ]
    }
   ],
   "source": [
    "with open(\"./mvtec_screws_v1.0/mvtec_screws.json\", \"r\") as f:\n",
    "    annots = json.load(f)\n",
    "\n",
    "annotations = annots[\"annotations\"]\n",
    "categories = annots[\"categories\"]\n",
    "images = annots[\"images\"]\n",
    "print(\"Objects \"+str(len(annotations)))\n",
    "print(\"Categories \"+str(len(categories)))\n",
    "print(\"Images \"+str(len(images)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = './mvtec_screws_v1.0/images'\n",
    "tfrecords_dir = \"tfrecords\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_count = sum([len(files) for r, d, files in os.walk(images_dir)])\n",
    "num_samples = len(images)\n",
    "num_tfrecords = file_count // num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _image_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    return tf.train.Feature(\n",
    "        bytes_list=tf.train.BytesList(value=[tf.io.encode_jpeg(value).numpy()])\n",
    "    )\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value.encode()]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def create_example(image, path, example):\n",
    "    feature = {\n",
    "        \"image\": _image_feature(image),\n",
    "        \"area\": _float_feature(example[\"area\"]),\n",
    "        \n",
    "        #Originally annotated as bounding boxes. Each box contains 5 parameters (row, col, width, height, phi)\n",
    "        \"row\": _float_feature(example[\"bbox\"][0]),\n",
    "        \"col\": _float_feature(example[\"bbox\"][1]),\n",
    "        \"width\": _float_feature(example[\"bbox\"][2]),\n",
    "        \"height\": _float_feature(example[\"bbox\"][3]),\n",
    "        \"phi\": _float_feature(example[\"bbox\"][4]),\n",
    "\n",
    "        \"category_id\": _int64_feature(example[\"category_id\"]),\n",
    "        \"id\": _int64_feature(example[\"id\"]),\n",
    "        \"image_id\": _int64_feature(example[\"image_id\"]),\n",
    "        \"is_crowd\": _int64_feature(example[\"is_crowd\"]),\n",
    "    }\n",
    "    return tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "\n",
    "\n",
    "def parse_tfrecord_fn(example):\n",
    "    feature_description = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"area\": tf.io.FixedLenFeature([], tf.float32),\n",
    "\n",
    "        #Originally annotated as bounding boxes. Each box contains 5 parameters (row, col, width, height, phi)\n",
    "        \"row\": tf.io.FixedLenFeature([], tf.float32),\n",
    "        \"col\": tf.io.FixedLenFeature([], tf.float32),\n",
    "        \"width\": tf.io.FixedLenFeature([], tf.float32),\n",
    "        \"height\": tf.io.FixedLenFeature([], tf.float32),\n",
    "        \"phi\": tf.io.FixedLenFeature([], tf.float32),\n",
    "\n",
    "        \"category_id\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        \"id\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        \"image_id\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        \"is_crowd\": tf.io.FixedLenFeature([], tf.int64),\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, feature_description)\n",
    "    example[\"image\"] = tf.io.decode_jpeg(example[\"image\"], channels=3)\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(tfrecords_dir):\n",
    "    os.makedirs(tfrecords_dir)  # creating TFRecords output folder\n",
    "for tfrec_num in range(num_tfrecords):\n",
    "    samples = annotations[(tfrec_num * num_samples) : ((tfrec_num + 1) * num_samples)]\n",
    "\n",
    "    with tf.io.TFRecordWriter(\n",
    "        tfrecords_dir + \"/file_%.2i-%i.tfrec\" % (tfrec_num, len(samples))\n",
    "    ) as writer:\n",
    "        for sample in samples:\n",
    "            for image in images:\n",
    "                if sample['image_id'] == image['id']:\n",
    "                    image_path = os.path.join(images_dir, image['file_name'])\n",
    "            image = tf.io.decode_jpeg(tf.io.read_file(image_path))\n",
    "            example = create_example(image, image_path, sample)\n",
    "            writer.write(example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "61c63460f299b72050a017299847de40e48391aa12573d6685850838867f4476"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
