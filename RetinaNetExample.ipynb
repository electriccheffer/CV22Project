{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RWA0Mn7k-NUq"
   },
   "source": [
    "# Object Detection with RetinaNet\n",
    "\n",
    "**Author:** [Srihari Humbarwadi](https://twitter.com/srihari_rh)<br>\n",
    "**Date created:** 2020/05/17<br>\n",
    "**Last modified:** 2020/07/14<br>\n",
    "**Description:** Implementing RetinaNet: Focal Loss for Dense Object Detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RABEGSjA-OU4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ioTBoXqh-NUt"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "Object detection a very important problem in computer\n",
    "vision. Here the model is tasked with localizing the objects present in an\n",
    "image, and at the same time, classifying them into different categories.\n",
    "Object detection models can be broadly classified into \"single-stage\" and\n",
    "\"two-stage\" detectors. Two-stage detectors are often more accurate but at the\n",
    "cost of being slower. Here in this example, we will implement RetinaNet,\n",
    "a popular single-stage detector, which is accurate and runs fast.\n",
    "RetinaNet uses a feature pyramid network to efficiently detect objects at\n",
    "multiple scales and introduces a new loss, the Focal loss function, to alleviate\n",
    "the problem of the extreme foreground-background class imbalance.\n",
    "\n",
    "**References:**\n",
    "\n",
    "- [RetinaNet Paper](https://arxiv.org/abs/1708.02002)\n",
    "- [Feature Pyramid Network Paper](https://arxiv.org/abs/1612.03144)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Xoo-1gG4-NUt"
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import re\n",
    "import zipfile\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_datasets as tfds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TTiaF7w0-NUu"
   },
   "source": [
    "## Downloading the COCO2017 dataset\n",
    "\n",
    "Training on the entire COCO2017 dataset which has around 118k images takes a\n",
    "lot of time, hence we will be using a smaller subset of ~500 images for\n",
    "training in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "GABZNoJp-NUv"
   },
   "outputs": [],
   "source": [
    "url = \"https://github.com/srihari-humbarwadi/datasets/releases/download/v0.1.0/data.zip\"\n",
    "filename = os.path.join(os.getcwd(), \"data.zip\")\n",
    "keras.utils.get_file(filename, url)\n",
    "\n",
    "\n",
    "with zipfile.ZipFile(\"data.zip\", \"r\") as z_fp:\n",
    "    z_fp.extractall(\"./\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V6xwJR6b-NUv"
   },
   "source": [
    "## Implementing utility functions\n",
    "\n",
    "Bounding boxes can be represented in multiple ways, the most common formats are:\n",
    "\n",
    "- Storing the coordinates of the corners `[xmin, ymin, xmax, ymax]`\n",
    "- Storing the coordinates of the center and the box dimensions\n",
    "`[x, y, width, height]`\n",
    "\n",
    "Since we require both formats, we will be implementing functions for converting\n",
    "between the formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "hxSN3O7q-NUw"
   },
   "outputs": [],
   "source": [
    "\n",
    "def swap_xy(boxes):\n",
    "    \"\"\"Swaps order the of x and y coordinates of the boxes.\n",
    "\n",
    "    Arguments:\n",
    "      boxes: A tensor with shape `(num_boxes, 4)` representing bounding boxes.\n",
    "\n",
    "    Returns:\n",
    "      swapped boxes with shape same as that of boxes.\n",
    "    \"\"\"\n",
    "    return tf.stack([boxes[:, 1], boxes[:, 0], boxes[:, 3], boxes[:, 2]], axis=-1)\n",
    "\n",
    "\n",
    "def convert_to_xywh(boxes):\n",
    "    \"\"\"Changes the box format to center, width and height.\n",
    "\n",
    "    Arguments:\n",
    "      boxes: A tensor of rank 2 or higher with a shape of `(..., num_boxes, 4)`\n",
    "        representing bounding boxes where each box is of the format\n",
    "        `[xmin, ymin, xmax, ymax]`.\n",
    "\n",
    "    Returns:\n",
    "      converted boxes with shape same as that of boxes.\n",
    "    \"\"\"\n",
    "    return tf.concat(\n",
    "        [(boxes[..., :2] + boxes[..., 2:]) / 2.0, boxes[..., 2:] - boxes[..., :2]],\n",
    "        axis=-1,\n",
    "    )\n",
    "\n",
    "\n",
    "def convert_to_corners(boxes):\n",
    "    \"\"\"Changes the box format to corner coordinates\n",
    "\n",
    "    Arguments:\n",
    "      boxes: A tensor of rank 2 or higher with a shape of `(..., num_boxes, 4)`\n",
    "        representing bounding boxes where each box is of the format\n",
    "        `[x, y, width, height]`.\n",
    "\n",
    "    Returns:\n",
    "      converted boxes with shape same as that of boxes.\n",
    "    \"\"\"\n",
    "    return tf.concat(\n",
    "        [boxes[..., :2] - boxes[..., 2:] / 2.0, boxes[..., :2] + boxes[..., 2:] / 2.0],\n",
    "        axis=-1,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BnAL1mWa-NUw"
   },
   "source": [
    "## Computing pairwise Intersection Over Union (IOU)\n",
    "\n",
    "As we will see later in the example, we would be assigning ground truth boxes\n",
    "to anchor boxes based on the extent of overlapping. This will require us to\n",
    "calculate the Intersection Over Union (IOU) between all the anchor\n",
    "boxes and ground truth boxes pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "5NQJWgo--NUx"
   },
   "outputs": [],
   "source": [
    "\n",
    "def compute_iou(boxes1, boxes2):\n",
    "    \"\"\"Computes pairwise IOU matrix for given two sets of boxes\n",
    "\n",
    "    Arguments:\n",
    "      boxes1: A tensor with shape `(N, 4)` representing bounding boxes\n",
    "        where each box is of the format `[x, y, width, height]`.\n",
    "        boxes2: A tensor with shape `(M, 4)` representing bounding boxes\n",
    "        where each box is of the format `[x, y, width, height]`.\n",
    "\n",
    "    Returns:\n",
    "      pairwise IOU matrix with shape `(N, M)`, where the value at ith row\n",
    "        jth column holds the IOU between ith box and jth box from\n",
    "        boxes1 and boxes2 respectively.\n",
    "    \"\"\"\n",
    "    boxes1_corners = convert_to_corners(boxes1)\n",
    "    boxes2_corners = convert_to_corners(boxes2)\n",
    "    lu = tf.maximum(boxes1_corners[:, None, :2], boxes2_corners[:, :2])\n",
    "    rd = tf.minimum(boxes1_corners[:, None, 2:], boxes2_corners[:, 2:])\n",
    "    intersection = tf.maximum(0.0, rd - lu)\n",
    "    intersection_area = intersection[:, :, 0] * intersection[:, :, 1]\n",
    "    boxes1_area = boxes1[:, 2] * boxes1[:, 3]\n",
    "    boxes2_area = boxes2[:, 2] * boxes2[:, 3]\n",
    "    union_area = tf.maximum(\n",
    "        boxes1_area[:, None] + boxes2_area - intersection_area, 1e-8\n",
    "    )\n",
    "    return tf.clip_by_value(intersection_area / union_area, 0.0, 1.0)\n",
    "\n",
    "\n",
    "def visualize_detections(\n",
    "    image, boxes, classes, scores, figsize=(7, 7), linewidth=1, color=[0, 0, 1]\n",
    "):\n",
    "    \"\"\"Visualize Detections\"\"\"\n",
    "    image = np.array(image, dtype=np.uint8)\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(image)\n",
    "    ax = plt.gca()\n",
    "    for box, _cls, score in zip(boxes, classes, scores):\n",
    "        text = \"{}: {:.2f}\".format(_cls, score)\n",
    "        x1, y1, x2, y2 = box\n",
    "        w, h = x2 - x1, y2 - y1\n",
    "        patch = plt.Rectangle(\n",
    "            [x1, y1], w, h, fill=False, edgecolor=color, linewidth=linewidth\n",
    "        )\n",
    "        ax.add_patch(patch)\n",
    "        ax.text(\n",
    "            x1,\n",
    "            y1,\n",
    "            text,\n",
    "            bbox={\"facecolor\": color, \"alpha\": 0.4},\n",
    "            clip_box=ax.clipbox,\n",
    "            clip_on=True,\n",
    "        )\n",
    "    plt.show()\n",
    "    return ax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uVuJiMFc-NUx"
   },
   "source": [
    "## Implementing Anchor generator\n",
    "\n",
    "Anchor boxes are fixed sized boxes that the model uses to predict the bounding\n",
    "box for an object. It does this by regressing the offset between the location\n",
    "of the object's center and the center of an anchor box, and then uses the width\n",
    "and height of the anchor box to predict a relative scale of the object. In the\n",
    "case of RetinaNet, each location on a given feature map has nine anchor boxes\n",
    "(at three scales and three ratios)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "DGTZF3Di-NUy"
   },
   "outputs": [],
   "source": [
    "\n",
    "class AnchorBox:\n",
    "    \"\"\"Generates anchor boxes.\n",
    "\n",
    "    This class has operations to generate anchor boxes for feature maps at\n",
    "    strides `[8, 16, 32, 64, 128]`. Where each anchor each box is of the\n",
    "    format `[x, y, width, height]`.\n",
    "\n",
    "    Attributes:\n",
    "      aspect_ratios: A list of float values representing the aspect ratios of\n",
    "        the anchor boxes at each location on the feature map\n",
    "      scales: A list of float values representing the scale of the anchor boxes\n",
    "        at each location on the feature map.\n",
    "      num_anchors: The number of anchor boxes at each location on feature map\n",
    "      areas: A list of float values representing the areas of the anchor\n",
    "        boxes for each feature map in the feature pyramid.\n",
    "      strides: A list of float value representing the strides for each feature\n",
    "        map in the feature pyramid.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.aspect_ratios = [0.5, 1.0, 2.0]\n",
    "        self.scales = [2 ** x for x in [0, 1 / 3, 2 / 3]]\n",
    "\n",
    "        self._num_anchors = len(self.aspect_ratios) * len(self.scales)\n",
    "        self._strides = [2 ** i for i in range(3, 8)]\n",
    "        self._areas = [x ** 2 for x in [32.0, 64.0, 128.0, 256.0, 512.0]]\n",
    "        self._anchor_dims = self._compute_dims()\n",
    "\n",
    "    def _compute_dims(self):\n",
    "        \"\"\"Computes anchor box dimensions for all ratios and scales at all levels\n",
    "        of the feature pyramid.\n",
    "        \"\"\"\n",
    "        anchor_dims_all = []\n",
    "        for area in self._areas:\n",
    "            anchor_dims = []\n",
    "            for ratio in self.aspect_ratios:\n",
    "                anchor_height = tf.math.sqrt(area / ratio)\n",
    "                anchor_width = area / anchor_height\n",
    "                dims = tf.reshape(\n",
    "                    tf.stack([anchor_width, anchor_height], axis=-1), [1, 1, 2]\n",
    "                )\n",
    "                for scale in self.scales:\n",
    "                    anchor_dims.append(scale * dims)\n",
    "            anchor_dims_all.append(tf.stack(anchor_dims, axis=-2))\n",
    "        return anchor_dims_all\n",
    "\n",
    "    def _get_anchors(self, feature_height, feature_width, level):\n",
    "        \"\"\"Generates anchor boxes for a given feature map size and level\n",
    "\n",
    "        Arguments:\n",
    "          feature_height: An integer representing the height of the feature map.\n",
    "          feature_width: An integer representing the width of the feature map.\n",
    "          level: An integer representing the level of the feature map in the\n",
    "            feature pyramid.\n",
    "\n",
    "        Returns:\n",
    "          anchor boxes with the shape\n",
    "          `(feature_height * feature_width * num_anchors, 4)`\n",
    "        \"\"\"\n",
    "        rx = tf.range(feature_width, dtype=tf.float32) + 0.5\n",
    "        ry = tf.range(feature_height, dtype=tf.float32) + 0.5\n",
    "        centers = tf.stack(tf.meshgrid(rx, ry), axis=-1) * self._strides[level - 3]\n",
    "        centers = tf.expand_dims(centers, axis=-2)\n",
    "        centers = tf.tile(centers, [1, 1, self._num_anchors, 1])\n",
    "        dims = tf.tile(\n",
    "            self._anchor_dims[level - 3], [feature_height, feature_width, 1, 1]\n",
    "        )\n",
    "        anchors = tf.concat([centers, dims], axis=-1)\n",
    "        return tf.reshape(\n",
    "            anchors, [feature_height * feature_width * self._num_anchors, 4]\n",
    "        )\n",
    "\n",
    "    def get_anchors(self, image_height, image_width):\n",
    "        \"\"\"Generates anchor boxes for all the feature maps of the feature pyramid.\n",
    "\n",
    "        Arguments:\n",
    "          image_height: Height of the input image.\n",
    "          image_width: Width of the input image.\n",
    "\n",
    "        Returns:\n",
    "          anchor boxes for all the feature maps, stacked as a single tensor\n",
    "            with shape `(total_anchors, 4)`\n",
    "        \"\"\"\n",
    "        anchors = [\n",
    "            self._get_anchors(\n",
    "                tf.math.ceil(image_height / 2 ** i),\n",
    "                tf.math.ceil(image_width / 2 ** i),\n",
    "                i,\n",
    "            )\n",
    "            for i in range(3, 8)\n",
    "        ]\n",
    "        return tf.concat(anchors, axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BxdDc0oW-NUy"
   },
   "source": [
    "## Preprocessing data\n",
    "\n",
    "Preprocessing the images involves two steps:\n",
    "\n",
    "- Resizing the image: Images are resized such that the shortest size is equal\n",
    "to 800 px, after resizing if the longest side of the image exceeds 1333 px,\n",
    "the image is resized such that the longest size is now capped at 1333 px.\n",
    "- Applying augmentation: Random scale jittering  and random horizontal flipping\n",
    "are the only augmentations applied to the images.\n",
    "\n",
    "Along with the images, bounding boxes are rescaled and flipped if required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "5hgTS80s-NUz"
   },
   "outputs": [],
   "source": [
    "\n",
    "def random_flip_horizontal(image, boxes):\n",
    "    \"\"\"Flips image and boxes horizontally with 50% chance\n",
    "\n",
    "    Arguments:\n",
    "      image: A 3-D tensor of shape `(height, width, channels)` representing an\n",
    "        image.\n",
    "      boxes: A tensor with shape `(num_boxes, 4)` representing bounding boxes,\n",
    "        having normalized coordinates.\n",
    "\n",
    "    Returns:\n",
    "      Randomly flipped image and boxes\n",
    "    \"\"\"\n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        image = tf.image.flip_left_right(image)\n",
    "        boxes = tf.stack(\n",
    "            [1 - boxes[:, 2], boxes[:, 1], 1 - boxes[:, 0], boxes[:, 3]], axis=-1\n",
    "        )\n",
    "    return image, boxes\n",
    "\n",
    "\n",
    "def resize_and_pad_image(\n",
    "    image, min_side=800.0, max_side=1333.0, jitter=[640, 1024], stride=128.0\n",
    "):\n",
    "    \"\"\"Resizes and pads image while preserving aspect ratio.\n",
    "\n",
    "    1. Resizes images so that the shorter side is equal to `min_side`\n",
    "    2. If the longer side is greater than `max_side`, then resize the image\n",
    "      with longer side equal to `max_side`\n",
    "    3. Pad with zeros on right and bottom to make the image shape divisible by\n",
    "    `stride`\n",
    "\n",
    "    Arguments:\n",
    "      image: A 3-D tensor of shape `(height, width, channels)` representing an\n",
    "        image.\n",
    "      min_side: The shorter side of the image is resized to this value, if\n",
    "        `jitter` is set to None.\n",
    "      max_side: If the longer side of the image exceeds this value after\n",
    "        resizing, the image is resized such that the longer side now equals to\n",
    "        this value.\n",
    "      jitter: A list of floats containing minimum and maximum size for scale\n",
    "        jittering. If available, the shorter side of the image will be\n",
    "        resized to a random value in this range.\n",
    "      stride: The stride of the smallest feature map in the feature pyramid.\n",
    "        Can be calculated using `image_size / feature_map_size`.\n",
    "\n",
    "    Returns:\n",
    "      image: Resized and padded image.\n",
    "      image_shape: Shape of the image before padding.\n",
    "      ratio: The scaling factor used to resize the image\n",
    "    \"\"\"\n",
    "    image_shape = tf.cast(tf.shape(image)[:2], dtype=tf.float32)\n",
    "    if jitter is not None:\n",
    "        min_side = tf.random.uniform((), jitter[0], jitter[1], dtype=tf.float32)\n",
    "    ratio = min_side / tf.reduce_min(image_shape)\n",
    "    if ratio * tf.reduce_max(image_shape) > max_side:\n",
    "        ratio = max_side / tf.reduce_max(image_shape)\n",
    "    image_shape = ratio * image_shape\n",
    "    image = tf.image.resize(image, tf.cast(image_shape, dtype=tf.int32))\n",
    "    padded_image_shape = tf.cast(\n",
    "        tf.math.ceil(image_shape / stride) * stride, dtype=tf.int32\n",
    "    )\n",
    "    image = tf.image.pad_to_bounding_box(\n",
    "        image, 0, 0, padded_image_shape[0], padded_image_shape[1]\n",
    "    )\n",
    "    return image, image_shape, ratio\n",
    "\n",
    "\n",
    "def preprocess_data(sample):\n",
    "    \"\"\"Applies preprocessing step to a single sample\n",
    "\n",
    "    Arguments:\n",
    "      sample: A dict representing a single training sample.\n",
    "\n",
    "    Returns:\n",
    "      image: Resized and padded image with random horizontal flipping applied.\n",
    "      bbox: Bounding boxes with the shape `(num_objects, 4)` where each box is\n",
    "        of the format `[x, y, width, height]`.\n",
    "      class_id: An tensor representing the class id of the objects, having\n",
    "        shape `(num_objects,)`.\n",
    "    \"\"\"\n",
    "    image = sample[\"image\"]\n",
    "    bbox = swap_xy(sample[\"objects\"][\"bbox\"])\n",
    "    class_id = tf.cast(sample[\"objects\"][\"label\"], dtype=tf.int32)\n",
    "\n",
    "    image, bbox = random_flip_horizontal(image, bbox)\n",
    "    image, image_shape, _ = resize_and_pad_image(image)\n",
    "\n",
    "    bbox = tf.stack(\n",
    "        [\n",
    "            bbox[:, 0] * image_shape[1],\n",
    "            bbox[:, 1] * image_shape[0],\n",
    "            bbox[:, 2] * image_shape[1],\n",
    "            bbox[:, 3] * image_shape[0],\n",
    "        ],\n",
    "        axis=-1,\n",
    "    )\n",
    "    bbox = convert_to_xywh(bbox)\n",
    "    return image, bbox, class_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gZjlFPor-NUz"
   },
   "source": [
    "## Encoding labels\n",
    "\n",
    "The raw labels, consisting of bounding boxes and class ids need to be\n",
    "transformed into targets for training. This transformation consists of\n",
    "the following steps:\n",
    "\n",
    "- Generating anchor boxes for the given image dimensions\n",
    "- Assigning ground truth boxes to the anchor boxes\n",
    "- The anchor boxes that are not assigned any objects, are either assigned the\n",
    "background class or ignored depending on the IOU\n",
    "- Generating the classification and regression targets using anchor boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "2aj19sFC-NUz"
   },
   "outputs": [],
   "source": [
    "\n",
    "class LabelEncoder:\n",
    "    \"\"\"Transforms the raw labels into targets for training.\n",
    "\n",
    "    This class has operations to generate targets for a batch of samples which\n",
    "    is made up of the input images, bounding boxes for the objects present and\n",
    "    their class ids.\n",
    "\n",
    "    Attributes:\n",
    "      anchor_box: Anchor box generator to encode the bounding boxes.\n",
    "      box_variance: The scaling factors used to scale the bounding box targets.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self._anchor_box = AnchorBox()\n",
    "        self._box_variance = tf.convert_to_tensor(\n",
    "            [0.1, 0.1, 0.2, 0.2], dtype=tf.float32\n",
    "        )\n",
    "\n",
    "    def _match_anchor_boxes(\n",
    "        self, anchor_boxes, gt_boxes, match_iou=0.5, ignore_iou=0.4\n",
    "    ):\n",
    "        \"\"\"Matches ground truth boxes to anchor boxes based on IOU.\n",
    "\n",
    "        1. Calculates the pairwise IOU for the M `anchor_boxes` and N `gt_boxes`\n",
    "          to get a `(M, N)` shaped matrix.\n",
    "        2. The ground truth box with the maximum IOU in each row is assigned to\n",
    "          the anchor box provided the IOU is greater than `match_iou`.\n",
    "        3. If the maximum IOU in a row is less than `ignore_iou`, the anchor\n",
    "          box is assigned with the background class.\n",
    "        4. The remaining anchor boxes that do not have any class assigned are\n",
    "          ignored during training.\n",
    "\n",
    "        Arguments:\n",
    "          anchor_boxes: A float tensor with the shape `(total_anchors, 4)`\n",
    "            representing all the anchor boxes for a given input image shape,\n",
    "            where each anchor box is of the format `[x, y, width, height]`.\n",
    "          gt_boxes: A float tensor with shape `(num_objects, 4)` representing\n",
    "            the ground truth boxes, where each box is of the format\n",
    "            `[x, y, width, height]`.\n",
    "          match_iou: A float value representing the minimum IOU threshold for\n",
    "            determining if a ground truth box can be assigned to an anchor box.\n",
    "          ignore_iou: A float value representing the IOU threshold under which\n",
    "            an anchor box is assigned to the background class.\n",
    "\n",
    "        Returns:\n",
    "          matched_gt_idx: Index of the matched object\n",
    "          positive_mask: A mask for anchor boxes that have been assigned ground\n",
    "            truth boxes.\n",
    "          ignore_mask: A mask for anchor boxes that need to by ignored during\n",
    "            training\n",
    "        \"\"\"\n",
    "        iou_matrix = compute_iou(anchor_boxes, gt_boxes)\n",
    "        max_iou = tf.reduce_max(iou_matrix, axis=1)\n",
    "        matched_gt_idx = tf.argmax(iou_matrix, axis=1)\n",
    "        positive_mask = tf.greater_equal(max_iou, match_iou)\n",
    "        negative_mask = tf.less(max_iou, ignore_iou)\n",
    "        ignore_mask = tf.logical_not(tf.logical_or(positive_mask, negative_mask))\n",
    "        return (\n",
    "            matched_gt_idx,\n",
    "            tf.cast(positive_mask, dtype=tf.float32),\n",
    "            tf.cast(ignore_mask, dtype=tf.float32),\n",
    "        )\n",
    "\n",
    "    def _compute_box_target(self, anchor_boxes, matched_gt_boxes):\n",
    "        \"\"\"Transforms the ground truth boxes into targets for training\"\"\"\n",
    "        box_target = tf.concat(\n",
    "            [\n",
    "                (matched_gt_boxes[:, :2] - anchor_boxes[:, :2]) / anchor_boxes[:, 2:],\n",
    "                tf.math.log(matched_gt_boxes[:, 2:] / anchor_boxes[:, 2:]),\n",
    "            ],\n",
    "            axis=-1,\n",
    "        )\n",
    "        box_target = box_target / self._box_variance\n",
    "        return box_target\n",
    "\n",
    "    def _encode_sample(self, image_shape, gt_boxes, cls_ids):\n",
    "        \"\"\"Creates box and classification targets for a single sample\"\"\"\n",
    "        anchor_boxes = self._anchor_box.get_anchors(image_shape[1], image_shape[2])\n",
    "        cls_ids = tf.cast(cls_ids, dtype=tf.float32)\n",
    "        matched_gt_idx, positive_mask, ignore_mask = self._match_anchor_boxes(\n",
    "            anchor_boxes, gt_boxes\n",
    "        )\n",
    "        matched_gt_boxes = tf.gather(gt_boxes, matched_gt_idx)\n",
    "        box_target = self._compute_box_target(anchor_boxes, matched_gt_boxes)\n",
    "        matched_gt_cls_ids = tf.gather(cls_ids, matched_gt_idx)\n",
    "        cls_target = tf.where(\n",
    "            tf.not_equal(positive_mask, 1.0), -1.0, matched_gt_cls_ids\n",
    "        )\n",
    "        cls_target = tf.where(tf.equal(ignore_mask, 1.0), -2.0, cls_target)\n",
    "        cls_target = tf.expand_dims(cls_target, axis=-1)\n",
    "        label = tf.concat([box_target, cls_target], axis=-1)\n",
    "        return label\n",
    "\n",
    "    def encode_batch(self, batch_images, gt_boxes, cls_ids):\n",
    "        \"\"\"Creates box and classification targets for a batch\"\"\"\n",
    "        images_shape = tf.shape(batch_images)\n",
    "        batch_size = images_shape[0]\n",
    "\n",
    "        labels = tf.TensorArray(dtype=tf.float32, size=batch_size, dynamic_size=True)\n",
    "        for i in range(batch_size):\n",
    "            label = self._encode_sample(images_shape, gt_boxes[i], cls_ids[i])\n",
    "            labels = labels.write(i, label)\n",
    "        batch_images = tf.keras.applications.resnet.preprocess_input(batch_images)\n",
    "        return batch_images, labels.stack()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YltWQ3if-NU0"
   },
   "source": [
    "## Building the ResNet50 backbone\n",
    "\n",
    "RetinaNet uses a ResNet based backbone, using which a feature pyramid network\n",
    "is constructed. In the example we use ResNet50 as the backbone, and return the\n",
    "feature maps at strides 8, 16 and 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "q3Luy60e-NU0"
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_backbone():\n",
    "    \"\"\"Builds ResNet50 with pre-trained imagenet weights\"\"\"\n",
    "    backbone = keras.applications.ResNet50(\n",
    "        include_top=False, input_shape=[None, None, 3]\n",
    "    )\n",
    "    c3_output, c4_output, c5_output = [\n",
    "        backbone.get_layer(layer_name).output\n",
    "        for layer_name in [\"conv3_block4_out\", \"conv4_block6_out\", \"conv5_block3_out\"]\n",
    "    ]\n",
    "    return keras.Model(\n",
    "        inputs=[backbone.inputs], outputs=[c3_output, c4_output, c5_output]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cxLdBCMa-NU0"
   },
   "source": [
    "## Building Feature Pyramid Network as a custom layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "2Mef-e5E-NU0"
   },
   "outputs": [],
   "source": [
    "\n",
    "class FeaturePyramid(keras.layers.Layer):\n",
    "    \"\"\"Builds the Feature Pyramid with the feature maps from the backbone.\n",
    "\n",
    "    Attributes:\n",
    "      num_classes: Number of classes in the dataset.\n",
    "      backbone: The backbone to build the feature pyramid from.\n",
    "        Currently supports ResNet50 only.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, backbone=None, **kwargs):\n",
    "        super(FeaturePyramid, self).__init__(name=\"FeaturePyramid\", **kwargs)\n",
    "        self.backbone = backbone if backbone else get_backbone()\n",
    "        self.conv_c3_1x1 = keras.layers.Conv2D(256, 1, 1, \"same\")\n",
    "        self.conv_c4_1x1 = keras.layers.Conv2D(256, 1, 1, \"same\")\n",
    "        self.conv_c5_1x1 = keras.layers.Conv2D(256, 1, 1, \"same\")\n",
    "        self.conv_c3_3x3 = keras.layers.Conv2D(256, 3, 1, \"same\")\n",
    "        self.conv_c4_3x3 = keras.layers.Conv2D(256, 3, 1, \"same\")\n",
    "        self.conv_c5_3x3 = keras.layers.Conv2D(256, 3, 1, \"same\")\n",
    "        self.conv_c6_3x3 = keras.layers.Conv2D(256, 3, 2, \"same\")\n",
    "        self.conv_c7_3x3 = keras.layers.Conv2D(256, 3, 2, \"same\")\n",
    "        self.upsample_2x = keras.layers.UpSampling2D(2)\n",
    "\n",
    "    def call(self, images, training=False):\n",
    "        c3_output, c4_output, c5_output = self.backbone(images, training=training)\n",
    "        p3_output = self.conv_c3_1x1(c3_output)\n",
    "        p4_output = self.conv_c4_1x1(c4_output)\n",
    "        p5_output = self.conv_c5_1x1(c5_output)\n",
    "        p4_output = p4_output + self.upsample_2x(p5_output)\n",
    "        p3_output = p3_output + self.upsample_2x(p4_output)\n",
    "        p3_output = self.conv_c3_3x3(p3_output)\n",
    "        p4_output = self.conv_c4_3x3(p4_output)\n",
    "        p5_output = self.conv_c5_3x3(p5_output)\n",
    "        p6_output = self.conv_c6_3x3(c5_output)\n",
    "        p7_output = self.conv_c7_3x3(tf.nn.relu(p6_output))\n",
    "        return p3_output, p4_output, p5_output, p6_output, p7_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "37aPcinX-NU0"
   },
   "source": [
    "## Building the classification and box regression heads.\n",
    "The RetinaNet model has separate heads for bounding box regression and\n",
    "for predicting class probabilities for the objects. These heads are shared\n",
    "between all the feature maps of the feature pyramid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "L6Cdj8EN-NU1"
   },
   "outputs": [],
   "source": [
    "\n",
    "def build_head(output_filters, bias_init):\n",
    "    \"\"\"Builds the class/box predictions head.\n",
    "\n",
    "    Arguments:\n",
    "      output_filters: Number of convolution filters in the final layer.\n",
    "      bias_init: Bias Initializer for the final convolution layer.\n",
    "\n",
    "    Returns:\n",
    "      A keras sequential model representing either the classification\n",
    "        or the box regression head depending on `output_filters`.\n",
    "    \"\"\"\n",
    "    head = keras.Sequential([keras.Input(shape=[None, None, 256])])\n",
    "    kernel_init = tf.initializers.RandomNormal(0.0, 0.01)\n",
    "    for _ in range(4):\n",
    "        head.add(\n",
    "            keras.layers.Conv2D(256, 3, padding=\"same\", kernel_initializer=kernel_init)\n",
    "        )\n",
    "        head.add(keras.layers.ReLU())\n",
    "    head.add(\n",
    "        keras.layers.Conv2D(\n",
    "            output_filters,\n",
    "            3,\n",
    "            1,\n",
    "            padding=\"same\",\n",
    "            kernel_initializer=kernel_init,\n",
    "            bias_initializer=bias_init,\n",
    "        )\n",
    "    )\n",
    "    return head\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VG6wcpUj-NU1"
   },
   "source": [
    "## Building RetinaNet using a subclassed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "_1v0rqmx-NU1"
   },
   "outputs": [],
   "source": [
    "\n",
    "class RetinaNet(keras.Model):\n",
    "    \"\"\"A subclassed Keras model implementing the RetinaNet architecture.\n",
    "\n",
    "    Attributes:\n",
    "      num_classes: Number of classes in the dataset.\n",
    "      backbone: The backbone to build the feature pyramid from.\n",
    "        Currently supports ResNet50 only.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_classes, backbone=None, **kwargs):\n",
    "        super(RetinaNet, self).__init__(name=\"RetinaNet\", **kwargs)\n",
    "        self.fpn = FeaturePyramid(backbone)\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        prior_probability = tf.constant_initializer(-np.log((1 - 0.01) / 0.01))\n",
    "        self.cls_head = build_head(9 * num_classes, prior_probability)\n",
    "        self.box_head = build_head(9 * 4, \"zeros\")\n",
    "\n",
    "    def call(self, image, training=False):\n",
    "        features = self.fpn(image, training=training)\n",
    "        N = tf.shape(image)[0]\n",
    "        cls_outputs = []\n",
    "        box_outputs = []\n",
    "        for feature in features:\n",
    "            box_outputs.append(tf.reshape(self.box_head(feature), [N, -1, 4]))\n",
    "            cls_outputs.append(\n",
    "                tf.reshape(self.cls_head(feature), [N, -1, self.num_classes])\n",
    "            )\n",
    "        cls_outputs = tf.concat(cls_outputs, axis=1)\n",
    "        box_outputs = tf.concat(box_outputs, axis=1)\n",
    "        return tf.concat([box_outputs, cls_outputs], axis=-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wuppex62-NU1"
   },
   "source": [
    "## Implementing a custom layer to decode predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "t8kVTSOO-NU1"
   },
   "outputs": [],
   "source": [
    "\n",
    "class DecodePredictions(tf.keras.layers.Layer):\n",
    "    \"\"\"A Keras layer that decodes predictions of the RetinaNet model.\n",
    "\n",
    "    Attributes:\n",
    "      num_classes: Number of classes in the dataset\n",
    "      confidence_threshold: Minimum class probability, below which detections\n",
    "        are pruned.\n",
    "      nms_iou_threshold: IOU threshold for the NMS operation\n",
    "      max_detections_per_class: Maximum number of detections to retain per\n",
    "       class.\n",
    "      max_detections: Maximum number of detections to retain across all\n",
    "        classes.\n",
    "      box_variance: The scaling factors used to scale the bounding box\n",
    "        predictions.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_classes=80,\n",
    "        confidence_threshold=0.05,\n",
    "        nms_iou_threshold=0.5,\n",
    "        max_detections_per_class=100,\n",
    "        max_detections=100,\n",
    "        box_variance=[0.1, 0.1, 0.2, 0.2],\n",
    "        **kwargs\n",
    "    ):\n",
    "        super(DecodePredictions, self).__init__(**kwargs)\n",
    "        self.num_classes = num_classes\n",
    "        self.confidence_threshold = confidence_threshold\n",
    "        self.nms_iou_threshold = nms_iou_threshold\n",
    "        self.max_detections_per_class = max_detections_per_class\n",
    "        self.max_detections = max_detections\n",
    "\n",
    "        self._anchor_box = AnchorBox()\n",
    "        self._box_variance = tf.convert_to_tensor(\n",
    "            [0.1, 0.1, 0.2, 0.2], dtype=tf.float32\n",
    "        )\n",
    "\n",
    "    def _decode_box_predictions(self, anchor_boxes, box_predictions):\n",
    "        boxes = box_predictions * self._box_variance\n",
    "        boxes = tf.concat(\n",
    "            [\n",
    "                boxes[:, :, :2] * anchor_boxes[:, :, 2:] + anchor_boxes[:, :, :2],\n",
    "                tf.math.exp(boxes[:, :, 2:]) * anchor_boxes[:, :, 2:],\n",
    "            ],\n",
    "            axis=-1,\n",
    "        )\n",
    "        boxes_transformed = convert_to_corners(boxes)\n",
    "        return boxes_transformed\n",
    "\n",
    "    def call(self, images, predictions):\n",
    "        image_shape = tf.cast(tf.shape(images), dtype=tf.float32)\n",
    "        anchor_boxes = self._anchor_box.get_anchors(image_shape[1], image_shape[2])\n",
    "        box_predictions = predictions[:, :, :4]\n",
    "        cls_predictions = tf.nn.sigmoid(predictions[:, :, 4:])\n",
    "        boxes = self._decode_box_predictions(anchor_boxes[None, ...], box_predictions)\n",
    "\n",
    "        return tf.image.combined_non_max_suppression(\n",
    "            tf.expand_dims(boxes, axis=2),\n",
    "            cls_predictions,\n",
    "            self.max_detections_per_class,\n",
    "            self.max_detections,\n",
    "            self.nms_iou_threshold,\n",
    "            self.confidence_threshold,\n",
    "            clip_boxes=False,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LPVHZjZk-NU2"
   },
   "source": [
    "## Implementing Smooth L1 loss and Focal Loss as keras custom losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "LUBiKyYs-NU2"
   },
   "outputs": [],
   "source": [
    "\n",
    "class RetinaNetBoxLoss(tf.losses.Loss):\n",
    "    \"\"\"Implements Smooth L1 loss\"\"\"\n",
    "\n",
    "    def __init__(self, delta):\n",
    "        super(RetinaNetBoxLoss, self).__init__(\n",
    "            reduction=\"none\", name=\"RetinaNetBoxLoss\"\n",
    "        )\n",
    "        self._delta = delta\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        difference = y_true - y_pred\n",
    "        absolute_difference = tf.abs(difference)\n",
    "        squared_difference = difference ** 2\n",
    "        loss = tf.where(\n",
    "            tf.less(absolute_difference, self._delta),\n",
    "            0.5 * squared_difference,\n",
    "            absolute_difference - 0.5,\n",
    "        )\n",
    "        return tf.reduce_sum(loss, axis=-1)\n",
    "\n",
    "\n",
    "class RetinaNetClassificationLoss(tf.losses.Loss):\n",
    "    \"\"\"Implements Focal loss\"\"\"\n",
    "\n",
    "    def __init__(self, alpha, gamma):\n",
    "        super(RetinaNetClassificationLoss, self).__init__(\n",
    "            reduction=\"none\", name=\"RetinaNetClassificationLoss\"\n",
    "        )\n",
    "        self._alpha = alpha\n",
    "        self._gamma = gamma\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            labels=y_true, logits=y_pred\n",
    "        )\n",
    "        probs = tf.nn.sigmoid(y_pred)\n",
    "        alpha = tf.where(tf.equal(y_true, 1.0), self._alpha, (1.0 - self._alpha))\n",
    "        pt = tf.where(tf.equal(y_true, 1.0), probs, 1 - probs)\n",
    "        loss = alpha * tf.pow(1.0 - pt, self._gamma) * cross_entropy\n",
    "        return tf.reduce_sum(loss, axis=-1)\n",
    "\n",
    "\n",
    "class RetinaNetLoss(tf.losses.Loss):\n",
    "    \"\"\"Wrapper to combine both the losses\"\"\"\n",
    "\n",
    "    def __init__(self, num_classes=80, alpha=0.25, gamma=2.0, delta=1.0):\n",
    "        super(RetinaNetLoss, self).__init__(reduction=\"auto\", name=\"RetinaNetLoss\")\n",
    "        self._clf_loss = RetinaNetClassificationLoss(alpha, gamma)\n",
    "        self._box_loss = RetinaNetBoxLoss(delta)\n",
    "        self._num_classes = num_classes\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        y_pred = tf.cast(y_pred, dtype=tf.float32)\n",
    "        box_labels = y_true[:, :, :4]\n",
    "        box_predictions = y_pred[:, :, :4]\n",
    "        cls_labels = tf.one_hot(\n",
    "            tf.cast(y_true[:, :, 4], dtype=tf.int32),\n",
    "            depth=self._num_classes,\n",
    "            dtype=tf.float32,\n",
    "        )\n",
    "        cls_predictions = y_pred[:, :, 4:]\n",
    "        positive_mask = tf.cast(tf.greater(y_true[:, :, 4], -1.0), dtype=tf.float32)\n",
    "        ignore_mask = tf.cast(tf.equal(y_true[:, :, 4], -2.0), dtype=tf.float32)\n",
    "        clf_loss = self._clf_loss(cls_labels, cls_predictions)\n",
    "        box_loss = self._box_loss(box_labels, box_predictions)\n",
    "        clf_loss = tf.where(tf.equal(ignore_mask, 1.0), 0.0, clf_loss)\n",
    "        box_loss = tf.where(tf.equal(positive_mask, 1.0), box_loss, 0.0)\n",
    "        normalizer = tf.reduce_sum(positive_mask, axis=-1)\n",
    "        clf_loss = tf.math.divide_no_nan(tf.reduce_sum(clf_loss, axis=-1), normalizer)\n",
    "        box_loss = tf.math.divide_no_nan(tf.reduce_sum(box_loss, axis=-1), normalizer)\n",
    "        loss = clf_loss + box_loss\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Vr5n7LN-NU2"
   },
   "source": [
    "## Setting up training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "lZunZ9i2-NU2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-16 19:24:34.899289: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-16 19:24:34.899960: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-16 19:24:34.907022: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-16 19:24:34.907424: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-16 19:24:34.908165: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-16 19:24:34.908515: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-16 19:24:34.909943: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-02-16 19:24:35.082140: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-16 19:24:35.082450: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-16 19:24:35.082894: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-16 19:24:35.083156: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-16 19:24:35.083569: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-16 19:24:35.083822: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-16 19:24:35.812094: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-16 19:24:35.812451: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-16 19:24:35.812939: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-16 19:24:35.813217: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-16 19:24:35.813691: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-16 19:24:35.813973: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 67 MB memory:  -> device: 0, name: GeForce GTX 1070, pci bus id: 0000:0d:00.0, compute capability: 6.1\n",
      "2022-02-16 19:24:35.814411: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-16 19:24:35.814856: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 5196 MB memory:  -> device: 1, name: GeForce GTX 1060 6GB, pci bus id: 0000:0c:00.0, compute capability: 6.1\n",
      "2022-02-16 19:24:35.818588: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 67.06M (70320128 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n"
     ]
    }
   ],
   "source": [
    "model_dir = \"retinanet/\"\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "num_classes = 80\n",
    "batch_size = 1\n",
    "\n",
    "learning_rates = [2.5e-06, 0.000625, 0.00125, 0.0025, 0.00025, 2.5e-05]\n",
    "learning_rate_boundaries = [125, 250, 500, 240000, 360000]\n",
    "learning_rate_fn = tf.optimizers.schedules.PiecewiseConstantDecay(\n",
    "    boundaries=learning_rate_boundaries, values=learning_rates\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XR5Bn3vm-NU2"
   },
   "source": [
    "## Initializing and compiling model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "DzSSFxK2-NU2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-16 19:24:46.573973: W tensorflow/core/common_runtime/bfc_allocator.cc:462] Allocator (GPU_0_bfc) ran out of memory trying to allocate 8.00MiB (rounded to 8388608)requested by op AddV2\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2022-02-16 19:24:46.574039: I tensorflow/core/common_runtime/bfc_allocator.cc:1010] BFCAllocator dump for GPU_0_bfc\n",
      "2022-02-16 19:24:46.574060: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (256): \tTotal Chunks: 85, Chunks in use: 85. 21.2KiB allocated for chunks. 21.2KiB in use in bin. 9.3KiB client-requested in use in bin.\n",
      "2022-02-16 19:24:46.574076: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (512): \tTotal Chunks: 40, Chunks in use: 40. 20.0KiB allocated for chunks. 20.0KiB in use in bin. 20.0KiB client-requested in use in bin.\n",
      "2022-02-16 19:24:46.574091: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (1024): \tTotal Chunks: 81, Chunks in use: 81. 81.2KiB allocated for chunks. 81.2KiB in use in bin. 81.0KiB client-requested in use in bin.\n",
      "2022-02-16 19:24:46.574105: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (2048): \tTotal Chunks: 25, Chunks in use: 25. 51.2KiB allocated for chunks. 51.2KiB in use in bin. 50.0KiB client-requested in use in bin.\n",
      "2022-02-16 19:24:46.574121: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (4096): \tTotal Chunks: 35, Chunks in use: 35. 140.0KiB allocated for chunks. 140.0KiB in use in bin. 140.0KiB client-requested in use in bin.\n",
      "2022-02-16 19:24:46.574134: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-02-16 19:24:46.574149: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (16384): \tTotal Chunks: 1, Chunks in use: 1. 26.5KiB allocated for chunks. 26.5KiB in use in bin. 16.0KiB client-requested in use in bin.\n",
      "2022-02-16 19:24:46.574163: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (32768): \tTotal Chunks: 1, Chunks in use: 1. 36.8KiB allocated for chunks. 36.8KiB in use in bin. 36.8KiB client-requested in use in bin.\n",
      "2022-02-16 19:24:46.574178: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (65536): \tTotal Chunks: 7, Chunks in use: 6. 495.5KiB allocated for chunks. 416.0KiB in use in bin. 384.0KiB client-requested in use in bin.\n",
      "2022-02-16 19:24:46.574192: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (131072): \tTotal Chunks: 5, Chunks in use: 4. 784.0KiB allocated for chunks. 560.0KiB in use in bin. 560.0KiB client-requested in use in bin.\n",
      "2022-02-16 19:24:46.574206: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (262144): \tTotal Chunks: 10, Chunks in use: 7. 2.69MiB allocated for chunks. 1.81MiB in use in bin. 1.75MiB client-requested in use in bin.\n",
      "2022-02-16 19:24:46.574219: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (524288): \tTotal Chunks: 8, Chunks in use: 6. 4.62MiB allocated for chunks. 3.25MiB in use in bin. 3.25MiB client-requested in use in bin.\n",
      "2022-02-16 19:24:46.574234: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (1048576): \tTotal Chunks: 14, Chunks in use: 11. 15.25MiB allocated for chunks. 11.75MiB in use in bin. 11.00MiB client-requested in use in bin.\n",
      "2022-02-16 19:24:46.574248: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (2097152): \tTotal Chunks: 8, Chunks in use: 7. 19.00MiB allocated for chunks. 15.50MiB in use in bin. 15.50MiB client-requested in use in bin.\n",
      "2022-02-16 19:24:46.574261: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-02-16 19:24:46.574275: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (8388608): \tTotal Chunks: 2, Chunks in use: 2. 17.18MiB allocated for chunks. 17.18MiB in use in bin. 16.00MiB client-requested in use in bin.\n",
      "2022-02-16 19:24:46.574287: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-02-16 19:24:46.574298: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-02-16 19:24:46.574310: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-02-16 19:24:46.574326: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-02-16 19:24:46.574338: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-02-16 19:24:46.574351: I tensorflow/core/common_runtime/bfc_allocator.cc:1033] Bin for 8.00MiB was 8.00MiB, Chunk State: \n",
      "2022-02-16 19:24:46.574360: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] Next region of size 63288320\n",
      "2022-02-16 19:24:46.574376: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888000000 of size 256 next 1\n",
      "2022-02-16 19:24:46.574385: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888000100 of size 1280 next 2\n",
      "2022-02-16 19:24:46.574394: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888000600 of size 256 next 3\n",
      "2022-02-16 19:24:46.574403: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888000700 of size 256 next 4\n",
      "2022-02-16 19:24:46.574412: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888000800 of size 256 next 14\n",
      "2022-02-16 19:24:46.574421: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888000900 of size 256 next 6\n",
      "2022-02-16 19:24:46.574430: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888000a00 of size 256 next 7\n",
      "2022-02-16 19:24:46.574438: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888000b00 of size 256 next 8\n",
      "2022-02-16 19:24:46.574447: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888000c00 of size 256 next 9\n",
      "2022-02-16 19:24:46.574456: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888000d00 of size 256 next 10\n",
      "2022-02-16 19:24:46.574465: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888000e00 of size 256 next 11\n",
      "2022-02-16 19:24:46.574474: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888000f00 of size 256 next 12\n",
      "2022-02-16 19:24:46.574482: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888001000 of size 256 next 13\n",
      "2022-02-16 19:24:46.574491: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888001100 of size 256 next 15\n",
      "2022-02-16 19:24:46.574500: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888001200 of size 256 next 5\n",
      "2022-02-16 19:24:46.574509: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888001300 of size 256 next 16\n",
      "2022-02-16 19:24:46.574518: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888001400 of size 256 next 17\n",
      "2022-02-16 19:24:46.574527: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888001500 of size 256 next 19\n",
      "2022-02-16 19:24:46.574536: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888001600 of size 256 next 18\n",
      "2022-02-16 19:24:46.574545: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888001700 of size 256 next 20\n",
      "2022-02-16 19:24:46.574554: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888001800 of size 256 next 21\n",
      "2022-02-16 19:24:46.574563: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888001900 of size 256 next 27\n",
      "2022-02-16 19:24:46.574571: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888001a00 of size 256 next 22\n",
      "2022-02-16 19:24:46.574580: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888001b00 of size 256 next 24\n",
      "2022-02-16 19:24:46.574589: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888001c00 of size 256 next 25\n",
      "2022-02-16 19:24:46.574599: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888001d00 of size 256 next 34\n",
      "2022-02-16 19:24:46.574608: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888001e00 of size 256 next 26\n",
      "2022-02-16 19:24:46.574616: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888001f00 of size 256 next 28\n",
      "2022-02-16 19:24:46.574627: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888002000 of size 256 next 29\n",
      "2022-02-16 19:24:46.574636: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888002100 of size 256 next 31\n",
      "2022-02-16 19:24:46.574645: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888002200 of size 256 next 35\n",
      "2022-02-16 19:24:46.574654: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888002300 of size 256 next 32\n",
      "2022-02-16 19:24:46.574663: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888002400 of size 256 next 33\n",
      "2022-02-16 19:24:46.574672: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888002500 of size 256 next 38\n",
      "2022-02-16 19:24:46.574681: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888002600 of size 256 next 39\n",
      "2022-02-16 19:24:46.574690: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888002700 of size 256 next 36\n",
      "2022-02-16 19:24:46.574698: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888002800 of size 256 next 37\n",
      "2022-02-16 19:24:46.574707: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888002900 of size 256 next 196\n",
      "2022-02-16 19:24:46.574717: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888002a00 of size 256 next 197\n",
      "2022-02-16 19:24:46.574727: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888002b00 of size 4096 next 198\n",
      "2022-02-16 19:24:46.574736: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888003b00 of size 4096 next 201\n",
      "2022-02-16 19:24:46.574744: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888004b00 of size 4096 next 202\n",
      "2022-02-16 19:24:46.574753: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888005b00 of size 4096 next 203\n",
      "2022-02-16 19:24:46.574762: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888006b00 of size 4096 next 204\n",
      "2022-02-16 19:24:46.574771: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888007b00 of size 1024 next 207\n",
      "2022-02-16 19:24:46.574780: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888007f00 of size 1024 next 208\n",
      "2022-02-16 19:24:46.574789: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888008300 of size 1024 next 209\n",
      "2022-02-16 19:24:46.574797: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888008700 of size 1024 next 210\n",
      "2022-02-16 19:24:46.574806: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888008b00 of size 1024 next 211\n",
      "2022-02-16 19:24:46.574815: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888008f00 of size 256 next 212\n",
      "2022-02-16 19:24:46.574823: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888009000 of size 256 next 213\n",
      "2022-02-16 19:24:46.574832: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888009100 of size 1024 next 216\n",
      "2022-02-16 19:24:46.574841: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888009500 of size 1024 next 217\n",
      "2022-02-16 19:24:46.574849: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888009900 of size 1024 next 218\n",
      "2022-02-16 19:24:46.574858: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888009d00 of size 1024 next 219\n",
      "2022-02-16 19:24:46.574867: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188800a100 of size 1024 next 220\n",
      "2022-02-16 19:24:46.574875: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188800a500 of size 256 next 221\n",
      "2022-02-16 19:24:46.574884: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188800a600 of size 256 next 222\n",
      "2022-02-16 19:24:46.574893: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188800a700 of size 4096 next 223\n",
      "2022-02-16 19:24:46.574901: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188800b700 of size 4096 next 225\n",
      "2022-02-16 19:24:46.574911: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188800c700 of size 4096 next 226\n",
      "2022-02-16 19:24:46.574920: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188800d700 of size 4096 next 227\n",
      "2022-02-16 19:24:46.574929: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188800e700 of size 4096 next 228\n",
      "2022-02-16 19:24:46.574937: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188800f700 of size 1024 next 229\n",
      "2022-02-16 19:24:46.574946: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188800fb00 of size 1024 next 231\n",
      "2022-02-16 19:24:46.574955: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188800ff00 of size 1024 next 232\n",
      "2022-02-16 19:24:46.574963: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888010300 of size 1024 next 233\n",
      "2022-02-16 19:24:46.574972: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888010700 of size 1024 next 234\n",
      "2022-02-16 19:24:46.574981: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888010b00 of size 1024 next 235\n",
      "2022-02-16 19:24:46.574989: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888010f00 of size 1024 next 238\n",
      "2022-02-16 19:24:46.574998: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888011300 of size 1024 next 239\n",
      "2022-02-16 19:24:46.575007: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888011700 of size 1024 next 240\n",
      "2022-02-16 19:24:46.575015: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888011b00 of size 1024 next 241\n",
      "2022-02-16 19:24:46.575024: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888011f00 of size 4096 next 242\n",
      "2022-02-16 19:24:46.575033: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888012f00 of size 4096 next 244\n",
      "2022-02-16 19:24:46.575041: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888013f00 of size 4096 next 23\n",
      "2022-02-16 19:24:46.575052: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888014f00 of size 37632 next 30\n",
      "2022-02-16 19:24:46.575061: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188801e200 of size 1024 next 42\n",
      "2022-02-16 19:24:46.575069: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188801e600 of size 1024 next 43\n",
      "2022-02-16 19:24:46.575078: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188801ea00 of size 1024 next 44\n",
      "2022-02-16 19:24:46.575087: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188801ee00 of size 1024 next 45\n",
      "2022-02-16 19:24:46.575095: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188801f200 of size 1024 next 46\n",
      "2022-02-16 19:24:46.575104: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188801f600 of size 256 next 47\n",
      "2022-02-16 19:24:46.575113: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188801f700 of size 256 next 48\n",
      "2022-02-16 19:24:46.575121: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188801f800 of size 256 next 49\n",
      "2022-02-16 19:24:46.575130: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188801f900 of size 256 next 51\n",
      "2022-02-16 19:24:46.575139: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188801fa00 of size 256 next 52\n",
      "2022-02-16 19:24:46.575147: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188801fb00 of size 256 next 53\n",
      "2022-02-16 19:24:46.575156: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188801fc00 of size 256 next 54\n",
      "2022-02-16 19:24:46.575164: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188801fd00 of size 256 next 55\n",
      "2022-02-16 19:24:46.575173: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188801fe00 of size 256 next 56\n",
      "2022-02-16 19:24:46.575182: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188801ff00 of size 256 next 59\n",
      "2022-02-16 19:24:46.575192: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888020000 of size 256 next 60\n",
      "2022-02-16 19:24:46.575201: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888020100 of size 256 next 61\n",
      "2022-02-16 19:24:46.575209: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888020200 of size 256 next 62\n",
      "2022-02-16 19:24:46.575218: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888020300 of size 1024 next 65\n",
      "2022-02-16 19:24:46.575227: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888020700 of size 1024 next 66\n",
      "2022-02-16 19:24:46.575236: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888020b00 of size 1024 next 67\n",
      "2022-02-16 19:24:46.575244: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888020f00 of size 1024 next 68\n",
      "2022-02-16 19:24:46.575253: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888021300 of size 1024 next 69\n",
      "2022-02-16 19:24:46.575262: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888021700 of size 256 next 71\n",
      "2022-02-16 19:24:46.575270: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888021800 of size 256 next 72\n",
      "2022-02-16 19:24:46.575279: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888021900 of size 256 next 73\n",
      "2022-02-16 19:24:46.575288: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888021a00 of size 256 next 74\n",
      "2022-02-16 19:24:46.575296: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888021b00 of size 256 next 75\n",
      "2022-02-16 19:24:46.575305: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888021c00 of size 256 next 76\n",
      "2022-02-16 19:24:46.575314: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888021d00 of size 256 next 79\n",
      "2022-02-16 19:24:46.575323: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888021e00 of size 256 next 80\n",
      "2022-02-16 19:24:46.575331: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888021f00 of size 256 next 81\n",
      "2022-02-16 19:24:46.575340: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888022000 of size 256 next 82\n",
      "2022-02-16 19:24:46.575349: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888022100 of size 1024 next 83\n",
      "2022-02-16 19:24:46.575358: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888022500 of size 1024 next 84\n",
      "2022-02-16 19:24:46.575366: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888022900 of size 1024 next 85\n",
      "2022-02-16 19:24:46.575375: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888022d00 of size 1024 next 86\n",
      "2022-02-16 19:24:46.575384: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888023100 of size 1024 next 87\n",
      "2022-02-16 19:24:46.575392: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888023500 of size 256 next 89\n",
      "2022-02-16 19:24:46.575401: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888023600 of size 256 next 90\n",
      "2022-02-16 19:24:46.575410: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888023700 of size 256 next 91\n",
      "2022-02-16 19:24:46.575418: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888023800 of size 256 next 92\n",
      "2022-02-16 19:24:46.575427: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888023900 of size 256 next 93\n",
      "2022-02-16 19:24:46.575436: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888023a00 of size 256 next 96\n",
      "2022-02-16 19:24:46.575444: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888023b00 of size 256 next 97\n",
      "2022-02-16 19:24:46.575453: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888023c00 of size 256 next 98\n",
      "2022-02-16 19:24:46.575462: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888023d00 of size 256 next 99\n",
      "2022-02-16 19:24:46.575472: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888023e00 of size 256 next 100\n",
      "2022-02-16 19:24:46.575481: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888023f00 of size 1024 next 102\n",
      "2022-02-16 19:24:46.575489: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888024300 of size 1024 next 103\n",
      "2022-02-16 19:24:46.575498: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888024700 of size 1024 next 104\n",
      "2022-02-16 19:24:46.575507: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888024b00 of size 1024 next 105\n",
      "2022-02-16 19:24:46.575515: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888024f00 of size 1024 next 106\n",
      "2022-02-16 19:24:46.575524: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888025300 of size 256 next 107\n",
      "2022-02-16 19:24:46.575534: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888025400 of size 256 next 108\n",
      "2022-02-16 19:24:46.575543: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888025500 of size 2048 next 109\n",
      "2022-02-16 19:24:46.575552: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888025d00 of size 2048 next 112\n",
      "2022-02-16 19:24:46.575561: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888026500 of size 2048 next 113\n",
      "2022-02-16 19:24:46.575570: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888026d00 of size 2816 next 50\n",
      "2022-02-16 19:24:46.575579: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888027800 of size 27136 next 40\n",
      "2022-02-16 19:24:46.575588: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188802e200 of size 65536 next 41\n",
      "2022-02-16 19:24:46.575597: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188803e200 of size 2048 next 114\n",
      "2022-02-16 19:24:46.575605: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188803ea00 of size 256 next 115\n",
      "2022-02-16 19:24:46.575614: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188803eb00 of size 256 next 116\n",
      "2022-02-16 19:24:46.575623: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188803ec00 of size 512 next 119\n",
      "2022-02-16 19:24:46.575632: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188803ee00 of size 512 next 120\n",
      "2022-02-16 19:24:46.575641: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188803f000 of size 512 next 121\n",
      "2022-02-16 19:24:46.575650: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188803f200 of size 512 next 122\n",
      "2022-02-16 19:24:46.575658: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188803f400 of size 512 next 123\n",
      "2022-02-16 19:24:46.575667: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188803f600 of size 256 next 124\n",
      "2022-02-16 19:24:46.575676: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188803f700 of size 256 next 125\n",
      "2022-02-16 19:24:46.575685: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188803f800 of size 512 next 128\n",
      "2022-02-16 19:24:46.575693: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188803fa00 of size 512 next 129\n",
      "2022-02-16 19:24:46.575702: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188803fc00 of size 512 next 130\n",
      "2022-02-16 19:24:46.575711: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188803fe00 of size 512 next 131\n",
      "2022-02-16 19:24:46.575719: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888040000 of size 512 next 132\n",
      "2022-02-16 19:24:46.575728: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888040200 of size 256 next 133\n",
      "2022-02-16 19:24:46.575737: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888040300 of size 256 next 134\n",
      "2022-02-16 19:24:46.575746: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888040400 of size 2048 next 135\n",
      "2022-02-16 19:24:46.575755: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888040c00 of size 2048 next 137\n",
      "2022-02-16 19:24:46.575763: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888041400 of size 2048 next 138\n",
      "2022-02-16 19:24:46.575772: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888041c00 of size 2048 next 139\n",
      "2022-02-16 19:24:46.575781: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888042400 of size 2048 next 140\n",
      "2022-02-16 19:24:46.575790: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888042c00 of size 512 next 141\n",
      "2022-02-16 19:24:46.575816: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888042e00 of size 512 next 143\n",
      "2022-02-16 19:24:46.575825: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888043000 of size 512 next 144\n",
      "2022-02-16 19:24:46.575834: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888043200 of size 512 next 145\n",
      "2022-02-16 19:24:46.575843: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888043400 of size 512 next 146\n",
      "2022-02-16 19:24:46.575851: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888043600 of size 512 next 147\n",
      "2022-02-16 19:24:46.575860: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888043800 of size 512 next 150\n",
      "2022-02-16 19:24:46.575869: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888043a00 of size 512 next 151\n",
      "2022-02-16 19:24:46.575877: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888043c00 of size 512 next 152\n",
      "2022-02-16 19:24:46.575886: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888043e00 of size 512 next 153\n",
      "2022-02-16 19:24:46.575895: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888044000 of size 2048 next 154\n",
      "2022-02-16 19:24:46.575903: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888044800 of size 2048 next 156\n",
      "2022-02-16 19:24:46.575912: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888045000 of size 2048 next 157\n",
      "2022-02-16 19:24:46.575921: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888045800 of size 2048 next 158\n",
      "2022-02-16 19:24:46.575930: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888046000 of size 2048 next 159\n",
      "2022-02-16 19:24:46.575938: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888046800 of size 512 next 161\n",
      "2022-02-16 19:24:46.575947: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888046a00 of size 512 next 162\n",
      "2022-02-16 19:24:46.575956: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888046c00 of size 512 next 163\n",
      "2022-02-16 19:24:46.575964: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888046e00 of size 512 next 164\n",
      "2022-02-16 19:24:46.575973: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888047000 of size 512 next 165\n",
      "2022-02-16 19:24:46.575982: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888047200 of size 512 next 168\n",
      "2022-02-16 19:24:46.575991: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888047400 of size 512 next 169\n",
      "2022-02-16 19:24:46.575999: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888047600 of size 512 next 170\n",
      "2022-02-16 19:24:46.576008: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888047800 of size 512 next 171\n",
      "2022-02-16 19:24:46.576017: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888047a00 of size 512 next 172\n",
      "2022-02-16 19:24:46.576025: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888047c00 of size 2048 next 174\n",
      "2022-02-16 19:24:46.576034: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888048400 of size 2048 next 175\n",
      "2022-02-16 19:24:46.576043: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888048c00 of size 2048 next 176\n",
      "2022-02-16 19:24:46.576051: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888049400 of size 2048 next 177\n",
      "2022-02-16 19:24:46.576060: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888049c00 of size 2048 next 178\n",
      "2022-02-16 19:24:46.576069: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188804a400 of size 512 next 179\n",
      "2022-02-16 19:24:46.576077: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188804a600 of size 512 next 180\n",
      "2022-02-16 19:24:46.576086: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188804a800 of size 512 next 181\n",
      "2022-02-16 19:24:46.576095: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188804aa00 of size 512 next 182\n",
      "2022-02-16 19:24:46.576103: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188804ac00 of size 512 next 183\n",
      "2022-02-16 19:24:46.576112: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188804ae00 of size 512 next 186\n",
      "2022-02-16 19:24:46.576121: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188804b000 of size 512 next 187\n",
      "2022-02-16 19:24:46.576129: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188804b200 of size 512 next 188\n",
      "2022-02-16 19:24:46.576138: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188804b400 of size 512 next 189\n",
      "2022-02-16 19:24:46.576147: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188804b600 of size 512 next 190\n",
      "2022-02-16 19:24:46.576155: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188804b800 of size 2048 next 192\n",
      "2022-02-16 19:24:46.576164: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188804c000 of size 2048 next 193\n",
      "2022-02-16 19:24:46.576173: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188804c800 of size 2048 next 194\n",
      "2022-02-16 19:24:46.576181: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188804d000 of size 2048 next 195\n",
      "2022-02-16 19:24:46.576191: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188804d800 of size 2560 next 64\n",
      "2022-02-16 19:24:46.576199: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188804e200 of size 65536 next 63\n",
      "2022-02-16 19:24:46.576208: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188805e200 of size 65536 next 70\n",
      "2022-02-16 19:24:46.576217: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188806e200 of size 98304 next 58\n",
      "2022-02-16 19:24:46.576226: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888086200 of size 147456 next 57\n",
      "2022-02-16 19:24:46.576235: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f18880aa200 of size 65536 next 88\n",
      "2022-02-16 19:24:46.576244: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7f18880ba200 of size 229376 next 78\n",
      "2022-02-16 19:24:46.576253: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f18880f2200 of size 147456 next 77\n",
      "2022-02-16 19:24:46.576262: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888116200 of size 65536 next 101\n",
      "2022-02-16 19:24:46.576271: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888126200 of size 4096 next 245\n",
      "2022-02-16 19:24:46.576280: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888127200 of size 4096 next 246\n",
      "2022-02-16 19:24:46.576289: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888128200 of size 1024 next 248\n",
      "2022-02-16 19:24:46.576297: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888128600 of size 1024 next 249\n",
      "2022-02-16 19:24:46.576306: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888128a00 of size 1024 next 250\n",
      "2022-02-16 19:24:46.576315: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888128e00 of size 1024 next 251\n",
      "2022-02-16 19:24:46.576323: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888129200 of size 1024 next 252\n",
      "2022-02-16 19:24:46.576334: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888129600 of size 1024 next 255\n",
      "2022-02-16 19:24:46.576342: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888129a00 of size 1024 next 256\n",
      "2022-02-16 19:24:46.576351: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888129e00 of size 1024 next 257\n",
      "2022-02-16 19:24:46.576360: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188812a200 of size 1024 next 258\n",
      "2022-02-16 19:24:46.576368: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188812a600 of size 1024 next 259\n",
      "2022-02-16 19:24:46.576377: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188812aa00 of size 4096 next 261\n",
      "2022-02-16 19:24:46.576385: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188812ba00 of size 4096 next 262\n",
      "2022-02-16 19:24:46.576394: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188812ca00 of size 4096 next 263\n",
      "2022-02-16 19:24:46.576403: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188812da00 of size 4096 next 264\n",
      "2022-02-16 19:24:46.576411: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188812ea00 of size 4096 next 265\n",
      "2022-02-16 19:24:46.576420: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188812fa00 of size 1024 next 266\n",
      "2022-02-16 19:24:46.576429: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188812fe00 of size 1024 next 267\n",
      "2022-02-16 19:24:46.576437: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888130200 of size 1024 next 268\n",
      "2022-02-16 19:24:46.576446: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888130600 of size 1024 next 269\n",
      "2022-02-16 19:24:46.576454: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888130a00 of size 1024 next 270\n",
      "2022-02-16 19:24:46.576463: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888130e00 of size 1024 next 273\n",
      "2022-02-16 19:24:46.576472: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888131200 of size 1024 next 274\n",
      "2022-02-16 19:24:46.576480: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888131600 of size 1024 next 275\n",
      "2022-02-16 19:24:46.576489: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888131a00 of size 1024 next 276\n",
      "2022-02-16 19:24:46.576498: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888131e00 of size 1024 next 277\n",
      "2022-02-16 19:24:46.576506: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888132200 of size 4096 next 279\n",
      "2022-02-16 19:24:46.576515: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888133200 of size 4096 next 280\n",
      "2022-02-16 19:24:46.576524: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888134200 of size 4096 next 281\n",
      "2022-02-16 19:24:46.576532: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888135200 of size 4096 next 282\n",
      "2022-02-16 19:24:46.576541: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888136200 of size 4096 next 283\n",
      "2022-02-16 19:24:46.576549: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888137200 of size 1024 next 284\n",
      "2022-02-16 19:24:46.576558: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888137600 of size 1024 next 285\n",
      "2022-02-16 19:24:46.576567: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888137a00 of size 1024 next 286\n",
      "2022-02-16 19:24:46.576575: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888137e00 of size 1024 next 287\n",
      "2022-02-16 19:24:46.576584: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888138200 of size 1024 next 288\n",
      "2022-02-16 19:24:46.576593: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888138600 of size 1024 next 291\n",
      "2022-02-16 19:24:46.576601: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888138a00 of size 1024 next 292\n",
      "2022-02-16 19:24:46.576610: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888138e00 of size 1024 next 293\n",
      "2022-02-16 19:24:46.576619: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888139200 of size 1024 next 294\n",
      "2022-02-16 19:24:46.576627: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888139600 of size 1024 next 295\n",
      "2022-02-16 19:24:46.576636: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888139a00 of size 1024 next 302\n",
      "2022-02-16 19:24:46.576645: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888139e00 of size 1024 next 95\n",
      "2022-02-16 19:24:46.576654: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188813a200 of size 147456 next 94\n",
      "2022-02-16 19:24:46.576662: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188815e200 of size 4096 next 297\n",
      "2022-02-16 19:24:46.576671: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188815f200 of size 4096 next 298\n",
      "2022-02-16 19:24:46.576680: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888160200 of size 4096 next 299\n",
      "2022-02-16 19:24:46.576689: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888161200 of size 4096 next 300\n",
      "2022-02-16 19:24:46.576697: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888162200 of size 4096 next 301\n",
      "2022-02-16 19:24:46.576706: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888163200 of size 1024 next 303\n",
      "2022-02-16 19:24:46.576715: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888163600 of size 1024 next 304\n",
      "2022-02-16 19:24:46.576724: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888163a00 of size 1024 next 305\n",
      "2022-02-16 19:24:46.576732: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888163e00 of size 1024 next 308\n",
      "2022-02-16 19:24:46.576741: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888164200 of size 1024 next 309\n",
      "2022-02-16 19:24:46.576750: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888164600 of size 1024 next 310\n",
      "2022-02-16 19:24:46.576758: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888164a00 of size 1024 next 311\n",
      "2022-02-16 19:24:46.576767: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888164e00 of size 1024 next 312\n",
      "2022-02-16 19:24:46.576776: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888165200 of size 4096 next 314\n",
      "2022-02-16 19:24:46.576785: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888166200 of size 4096 next 315\n",
      "2022-02-16 19:24:46.576793: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888167200 of size 4096 next 316\n",
      "2022-02-16 19:24:46.576802: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888168200 of size 4096 next 317\n",
      "2022-02-16 19:24:46.576812: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888169200 of size 4096 next 318\n",
      "2022-02-16 19:24:46.576821: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188816a200 of size 256 next 319\n",
      "2022-02-16 19:24:46.576830: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188816a300 of size 256 next 320\n",
      "2022-02-16 19:24:46.576839: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7f188816a400 of size 81408 next 118\n",
      "2022-02-16 19:24:46.576849: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188817e200 of size 131072 next 117\n",
      "2022-02-16 19:24:46.576858: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188819e200 of size 262144 next 136\n",
      "2022-02-16 19:24:46.576867: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7f18881de200 of size 262144 next 155\n",
      "2022-02-16 19:24:46.576875: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188821e200 of size 262144 next 111\n",
      "2022-02-16 19:24:46.576885: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188825e200 of size 524288 next 110\n",
      "2022-02-16 19:24:46.576894: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f18882de200 of size 262144 next 142\n",
      "2022-02-16 19:24:46.576903: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7f188831e200 of size 327680 next 127\n",
      "2022-02-16 19:24:46.576912: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188836e200 of size 589824 next 126\n",
      "2022-02-16 19:24:46.576921: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f18883fe200 of size 262144 next 160\n",
      "2022-02-16 19:24:46.576930: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7f188843e200 of size 917504 next 149\n",
      "2022-02-16 19:24:46.576939: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188851e200 of size 589824 next 148\n",
      "2022-02-16 19:24:46.576948: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f18885ae200 of size 262144 next 173\n",
      "2022-02-16 19:24:46.576957: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f18885ee200 of size 327680 next 167\n",
      "2022-02-16 19:24:46.576966: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188863e200 of size 589824 next 166\n",
      "2022-02-16 19:24:46.576975: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f18886ce200 of size 262144 next 191\n",
      "2022-02-16 19:24:46.576984: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7f188870e200 of size 327680 next 185\n",
      "2022-02-16 19:24:46.576993: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188875e200 of size 589824 next 184\n",
      "2022-02-16 19:24:46.577002: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7f18887ee200 of size 524288 next 206\n",
      "2022-02-16 19:24:46.577011: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188886e200 of size 524288 next 205\n",
      "2022-02-16 19:24:46.577020: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f18888ee200 of size 1048576 next 224\n",
      "2022-02-16 19:24:46.577029: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7f18889ee200 of size 1048576 next 243\n",
      "2022-02-16 19:24:46.577038: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888aee200 of size 1048576 next 200\n",
      "2022-02-16 19:24:46.577047: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888bee200 of size 2097152 next 199\n",
      "2022-02-16 19:24:46.577056: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1888dee200 of size 1048576 next 230\n",
      "2022-02-16 19:24:46.577065: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7f1888eee200 of size 1310720 next 215\n",
      "2022-02-16 19:24:46.577075: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188902e200 of size 2359296 next 214\n",
      "2022-02-16 19:24:46.577084: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188926e200 of size 1048576 next 247\n",
      "2022-02-16 19:24:46.577093: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7f188936e200 of size 3670016 next 237\n",
      "2022-02-16 19:24:46.577102: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f18896ee200 of size 2359296 next 236\n",
      "2022-02-16 19:24:46.577111: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188992e200 of size 1048576 next 260\n",
      "2022-02-16 19:24:46.577120: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1889a2e200 of size 1310720 next 254\n",
      "2022-02-16 19:24:46.577129: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1889b6e200 of size 2359296 next 253\n",
      "2022-02-16 19:24:46.577137: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1889dae200 of size 1048576 next 278\n",
      "2022-02-16 19:24:46.577146: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1889eae200 of size 1310720 next 272\n",
      "2022-02-16 19:24:46.577155: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1889fee200 of size 2359296 next 271\n",
      "2022-02-16 19:24:46.577165: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188a22e200 of size 1048576 next 296\n",
      "2022-02-16 19:24:46.577174: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188a32e200 of size 1310720 next 290\n",
      "2022-02-16 19:24:46.577183: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188a46e200 of size 2359296 next 289\n",
      "2022-02-16 19:24:46.577191: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188a6ae200 of size 1048576 next 313\n",
      "2022-02-16 19:24:46.577200: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7f188a7ae200 of size 1310720 next 307\n",
      "2022-02-16 19:24:46.577209: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188a8ee200 of size 2359296 next 306\n",
      "2022-02-16 19:24:46.577218: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188ab2e200 of size 8388608 next 321\n",
      "2022-02-16 19:24:46.577228: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f188b32e200 of size 9622016 next 18446744073709551615\n",
      "2022-02-16 19:24:46.577236: I tensorflow/core/common_runtime/bfc_allocator.cc:1071]      Summary of in-use Chunks by size: \n",
      "2022-02-16 19:24:46.577249: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 85 Chunks of size 256 totalling 21.2KiB\n",
      "2022-02-16 19:24:46.577261: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 40 Chunks of size 512 totalling 20.0KiB\n",
      "2022-02-16 19:24:46.577272: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 80 Chunks of size 1024 totalling 80.0KiB\n",
      "2022-02-16 19:24:46.577282: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2022-02-16 19:24:46.577293: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 23 Chunks of size 2048 totalling 46.0KiB\n",
      "2022-02-16 19:24:46.577304: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 2560 totalling 2.5KiB\n",
      "2022-02-16 19:24:46.577314: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 2816 totalling 2.8KiB\n",
      "2022-02-16 19:24:46.577325: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 35 Chunks of size 4096 totalling 140.0KiB\n",
      "2022-02-16 19:24:46.577336: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 27136 totalling 26.5KiB\n",
      "2022-02-16 19:24:46.577347: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 37632 totalling 36.8KiB\n",
      "2022-02-16 19:24:46.577358: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 5 Chunks of size 65536 totalling 320.0KiB\n",
      "2022-02-16 19:24:46.577368: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 98304 totalling 96.0KiB\n",
      "2022-02-16 19:24:46.577379: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 131072 totalling 128.0KiB\n",
      "2022-02-16 19:24:46.577390: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 3 Chunks of size 147456 totalling 432.0KiB\n",
      "2022-02-16 19:24:46.577400: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 6 Chunks of size 262144 totalling 1.50MiB\n",
      "2022-02-16 19:24:46.577411: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 327680 totalling 320.0KiB\n",
      "2022-02-16 19:24:46.577422: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 2 Chunks of size 524288 totalling 1.00MiB\n",
      "2022-02-16 19:24:46.577432: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 4 Chunks of size 589824 totalling 2.25MiB\n",
      "2022-02-16 19:24:46.577443: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 8 Chunks of size 1048576 totalling 8.00MiB\n",
      "2022-02-16 19:24:46.577453: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 3 Chunks of size 1310720 totalling 3.75MiB\n",
      "2022-02-16 19:24:46.577463: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 2097152 totalling 2.00MiB\n",
      "2022-02-16 19:24:46.577474: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 6 Chunks of size 2359296 totalling 13.50MiB\n",
      "2022-02-16 19:24:46.577485: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 8388608 totalling 8.00MiB\n",
      "2022-02-16 19:24:46.577495: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 9622016 totalling 9.18MiB\n",
      "2022-02-16 19:24:46.577506: I tensorflow/core/common_runtime/bfc_allocator.cc:1078] Sum Total of in-use chunks: 50.81MiB\n",
      "2022-02-16 19:24:46.577515: I tensorflow/core/common_runtime/bfc_allocator.cc:1080] total_region_allocated_bytes_: 63288320 memory_limit_: 70320128 available bytes: 7031808 curr_region_allocation_bytes_: 140640256\n",
      "2022-02-16 19:24:46.577531: I tensorflow/core/common_runtime/bfc_allocator.cc:1086] Stats: \n",
      "Limit:                        70320128\n",
      "InUse:                        53278208\n",
      "MaxInUse:                     53278464\n",
      "NumAllocs:                         531\n",
      "MaxAllocSize:                  9622016\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2022-02-16 19:24:46.577553: W tensorflow/core/common_runtime/bfc_allocator.cc:474] *****************_*******_*******____*****************************_********************************x\n",
      "2022-02-16 19:24:46.577590: W tensorflow/core/framework/op_kernel.cc:1733] RESOURCE_EXHAUSTED: failed to allocate memory\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "failed to allocate memory [Op:AddV2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_18919/3336347397.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresnet50_backbone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_backbone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRetinaNetLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRetinaNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresnet50_backbone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_18919/2844598433.py\u001b[0m in \u001b[0;36mget_backbone\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_backbone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"\"\"Builds ResNet50 with pre-trained imagenet weights\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     backbone = keras.applications.ResNet50(\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     )\n",
      "\u001b[0;32m~/.python_venv/tf_testing/lib/python3.9/site-packages/keras/applications/resnet.py\u001b[0m in \u001b[0;36mResNet50\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes, **kwargs)\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstack1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'conv5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m   return ResNet(stack_fn, False, True, 'resnet50', include_top, weights,\n\u001b[0m\u001b[1;32m    459\u001b[0m                 input_tensor, input_shape, pooling, classes, **kwargs)\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.python_venv/tf_testing/lib/python3.9/site-packages/keras/applications/resnet.py\u001b[0m in \u001b[0;36mResNet\u001b[0;34m(stack_fn, preact, use_bias, model_name, include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m   \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pool1_pool'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m   \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mpreact\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.python_venv/tf_testing/lib/python3.9/site-packages/keras/applications/resnet.py\u001b[0m in \u001b[0;36mstack_fn\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'conv3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'conv4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mstack1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'conv5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m   return ResNet(stack_fn, False, True, 'resnet50', include_top, weights,\n",
      "\u001b[0;32m~/.python_venv/tf_testing/lib/python3.9/site-packages/keras/applications/resnet.py\u001b[0m in \u001b[0;36mstack1\u001b[0;34m(x, filters, blocks, stride1, name)\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0mOutput\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mstacked\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m   \"\"\"\n\u001b[0;32m--> 271\u001b[0;31m   \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstride1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_block1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblocks\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv_shortcut\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_block'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.python_venv/tf_testing/lib/python3.9/site-packages/keras/applications/resnet.py\u001b[0m in \u001b[0;36mblock1\u001b[0;34m(x, filters, kernel_size, stride, conv_shortcut, name)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mconv_shortcut\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m     shortcut = layers.Conv2D(\n\u001b[0m\u001b[1;32m    232\u001b[0m         4 * filters, 1, strides=stride, name=name + '_0_conv')(x)\n\u001b[1;32m    233\u001b[0m     shortcut = layers.BatchNormalization(\n",
      "\u001b[0;32m~/.python_venv/tf_testing/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.python_venv/tf_testing/lib/python3.9/site-packages/keras/backend.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[0;34m(self, shape, minval, maxval, dtype)\u001b[0m\n\u001b[1;32m   1829\u001b[0m       return self._generator.uniform(\n\u001b[1;32m   1830\u001b[0m           shape=shape, minval=minval, maxval=maxval, dtype=dtype)\n\u001b[0;32m-> 1831\u001b[0;31m     return tf.random.uniform(\n\u001b[0m\u001b[1;32m   1832\u001b[0m         \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mminval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1833\u001b[0m         seed=self.make_legacy_seed())\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: failed to allocate memory [Op:AddV2]"
     ]
    }
   ],
   "source": [
    "resnet50_backbone = get_backbone()\n",
    "loss_fn = RetinaNetLoss(num_classes)\n",
    "model = RetinaNet(num_classes, resnet50_backbone)\n",
    "\n",
    "optimizer = tf.optimizers.SGD(learning_rate=learning_rate_fn, momentum=0.9)\n",
    "model.compile(loss=loss_fn, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_WYNvsxU-NU3"
   },
   "source": [
    "## Setting up callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zb4hFwRY-NU3"
   },
   "outputs": [],
   "source": [
    "callbacks_list = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=os.path.join(model_dir, \"weights\" + \"_epoch_{epoch}\"),\n",
    "        monitor=\"loss\",\n",
    "        save_best_only=False,\n",
    "        save_weights_only=True,\n",
    "        verbose=1,\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XKJVPNXE-NU3"
   },
   "source": [
    "## Load the COCO2017 dataset using TensorFlow Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WpRCJxTt-NU3"
   },
   "outputs": [],
   "source": [
    "#  set `data_dir=None` to load the complete dataset\n",
    "\n",
    "(train_dataset, val_dataset), dataset_info = tfds.load(\n",
    "    \"coco/2017\", split=[\"train\", \"validation\"], with_info=True, data_dir=\"data\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sz-umE0x-NU3"
   },
   "source": [
    "## Setting up a `tf.data` pipeline\n",
    "\n",
    "To ensure that the model is fed with data efficiently we will be using\n",
    "`tf.data` API to create our input pipeline. The input pipeline\n",
    "consists for the following major processing steps:\n",
    "\n",
    "- Apply the preprocessing function to the samples\n",
    "- Create batches with fixed batch size. Since images in the batch can\n",
    "have different dimensions, and can also have different number of\n",
    "objects, we use `padded_batch` to the add the necessary padding to create\n",
    "rectangular tensors\n",
    "- Create targets for each sample in the batch using `LabelEncoder`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A3KBdtnn-NU3"
   },
   "outputs": [],
   "source": [
    "autotune = tf.data.AUTOTUNE\n",
    "train_dataset = train_dataset.map(preprocess_data, num_parallel_calls=autotune)\n",
    "train_dataset = train_dataset.shuffle(8 * batch_size)\n",
    "train_dataset = train_dataset.padded_batch(\n",
    "    batch_size=batch_size, padding_values=(0.0, 1e-8, -1), drop_remainder=True\n",
    ")\n",
    "train_dataset = train_dataset.map(\n",
    "    label_encoder.encode_batch, num_parallel_calls=autotune\n",
    ")\n",
    "train_dataset = train_dataset.apply(tf.data.experimental.ignore_errors())\n",
    "train_dataset = train_dataset.prefetch(autotune)\n",
    "\n",
    "val_dataset = val_dataset.map(preprocess_data, num_parallel_calls=autotune)\n",
    "val_dataset = val_dataset.padded_batch(\n",
    "    batch_size=1, padding_values=(0.0, 1e-8, -1), drop_remainder=True\n",
    ")\n",
    "val_dataset = val_dataset.map(label_encoder.encode_batch, num_parallel_calls=autotune)\n",
    "val_dataset = val_dataset.apply(tf.data.experimental.ignore_errors())\n",
    "val_dataset = val_dataset.prefetch(autotune)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c8Ov4Psw-NU3"
   },
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hgs1CYEi-NU4"
   },
   "outputs": [],
   "source": [
    "# Uncomment the following lines, when training on full dataset\n",
    "# train_steps_per_epoch = dataset_info.splits[\"train\"].num_examples // batch_size\n",
    "# val_steps_per_epoch = \\\n",
    "#     dataset_info.splits[\"validation\"].num_examples // batch_size\n",
    "\n",
    "# train_steps = 4 * 100000\n",
    "# epochs = train_steps // train_steps_per_epoch\n",
    "\n",
    "epochs = 1\n",
    "\n",
    "# Running 100 training and 50 validation steps,\n",
    "# remove `.take` when training on the full dataset\n",
    "\n",
    "model.fit(\n",
    "    train_dataset.take(100),\n",
    "    validation_data=val_dataset.take(50),\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks_list,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nUdLTCRt-NU4"
   },
   "source": [
    "## Loading weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YThOcEjj-NU4"
   },
   "outputs": [],
   "source": [
    "# Change this to `model_dir` when not using the downloaded weights\n",
    "weights_dir = \"data\"\n",
    "\n",
    "latest_checkpoint = tf.train.latest_checkpoint(weights_dir)\n",
    "model.load_weights(latest_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JpdNz11f-NU4"
   },
   "source": [
    "## Building inference model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2TOMiyat-NU4"
   },
   "outputs": [],
   "source": [
    "image = tf.keras.Input(shape=[None, None, 3], name=\"image\")\n",
    "predictions = model(image, training=False)\n",
    "detections = DecodePredictions(confidence_threshold=0.5)(image, predictions)\n",
    "inference_model = tf.keras.Model(inputs=image, outputs=detections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mhNwtjxR-NU4"
   },
   "source": [
    "## Generating detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hv97MAz9-NU4"
   },
   "outputs": [],
   "source": [
    "\n",
    "def prepare_image(image):\n",
    "    image, _, ratio = resize_and_pad_image(image, jitter=None)\n",
    "    image = tf.keras.applications.resnet.preprocess_input(image)\n",
    "    return tf.expand_dims(image, axis=0), ratio\n",
    "\n",
    "\n",
    "val_dataset = tfds.load(\"coco/2017\", split=\"validation\", data_dir=\"data\")\n",
    "int2str = dataset_info.features[\"objects\"][\"label\"].int2str\n",
    "\n",
    "for sample in val_dataset.take(2):\n",
    "    image = tf.cast(sample[\"image\"], dtype=tf.float32)\n",
    "    input_image, ratio = prepare_image(image)\n",
    "    detections = inference_model.predict(input_image)\n",
    "    num_detections = detections.valid_detections[0]\n",
    "    class_names = [\n",
    "        int2str(int(x)) for x in detections.nmsed_classes[0][:num_detections]\n",
    "    ]\n",
    "    visualize_detections(\n",
    "        image,\n",
    "        detections.nmsed_boxes[0][:num_detections] / ratio,\n",
    "        class_names,\n",
    "        detections.nmsed_scores[0][:num_detections],\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of retinanet",
   "provenance": [
    {
     "file_id": "https://github.com/keras-team/keras-io/blob/master/examples/vision/ipynb/retinanet.ipynb",
     "timestamp": 1645039119399
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "TensorFlow Testing",
   "language": "python",
   "name": "tf-testing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
