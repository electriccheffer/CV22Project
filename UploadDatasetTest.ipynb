{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UploadDatasetTest.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil"
      ],
      "metadata": {
        "id": "Gm2aXEl9Pdbb"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWSJpsyKqHjH",
        "outputId": "d70da78c-b169-4943-c761-6b24c22c8228"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/My\\ Drive/mvtec_screws/\n",
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwP3qeOKYupq",
        "outputId": "ccf0e7ec-d35f-4f94-bf14-ab36de7a9d38"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/mvtec_screws\n",
            "/content/drive/My Drive/mvtec_screws\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"./mvtec_screws.json\", \"r\") as f:\n",
        "    annots = json.load(f)\n",
        "\n",
        "annotations = annots[\"annotations\"]\n",
        "categories = annots[\"categories\"]\n",
        "images = annots[\"images\"]\n",
        "print(\"Objects \"+str(len(annotations)))\n",
        "print(\"Categories \"+str(len(categories)))\n",
        "print(\"Images \"+str(len(images)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WukyUzEnPpdr",
        "outputId": "95e2f69e-c10d-41c9-9fba-d4e07da11de0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Objects 4427\n",
            "Categories 13\n",
            "Images 384\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images_dir = './images'\n",
        "tfrecords_dir = \"tfrecords\""
      ],
      "metadata": {
        "id": "lYB7YHN_PtKL"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_count = sum([len(files) for r, d, files in os.walk(images_dir)])\n",
        "num_samples = len(images)\n",
        "num_tfrecords = file_count // num_samples\n",
        "print(num_tfrecords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j13g-VcLPuKP",
        "outputId": "01666be1-4807-4f81-f16d-5679908972d9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def _image_feature(value):\n",
        "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
        "    return tf.train.Feature(\n",
        "        bytes_list=tf.train.BytesList(value=[tf.io.encode_png(value).numpy()])\n",
        "    )\n",
        "\n",
        "def _bytes_feature(value):\n",
        "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
        "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value.encode()]))\n",
        "\n",
        "def _int64_feature(value):\n",
        "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
        "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
        "def _int64_list(value):\n",
        "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
        "    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
        "\n",
        "def _float_feature(value):\n",
        "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
        "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
        "\n",
        "def _float_list(value):\n",
        "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
        "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
        "\n",
        "def create_example(image, path, example):\n",
        "    feature = {\n",
        "        \"image\": _image_feature(image),\n",
        "        \"area\": _float_list(example[\"area\"]),\n",
        "        \n",
        "        #Originally annotated as bounding boxes. Each box contains 5 parameters (row, col, width, height, phi)\n",
        "        \"row\": _float_list(example[\"row\"]),\n",
        "        \"col\": _float_list(example[\"col\"]),\n",
        "        \"width\": _float_list(example[\"width\"]),\n",
        "        \"height\": _float_list(example[\"height\"]),\n",
        "        \"phi\": _float_list(example[\"phi\"]),\n",
        "\n",
        "        \"category_id\": _int64_list(example[\"category_id\"]),\n",
        "        \"id\": _int64_list(example[\"id\"]),\n",
        "        \"image_id\": _int64_feature(example[\"image_id\"]),\n",
        "        \"is_crowd\": _int64_list(example[\"is_crowd\"]),\n",
        "    }\n",
        "    return tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "\n",
        "\n",
        "def parse_tfrecord_fn(example):\n",
        "    feature_description = {\n",
        "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
        "        \"area\": tf.io.FixedLenFeature([], tf.float32),\n",
        "\n",
        "        #Originally annotated as bounding boxes. Each box contains 5 parameters (row, col, width, height, phi)\n",
        "        \"row\": tf.io.FixedLenFeature([], tf.float32),\n",
        "        \"col\": tf.io.FixedLenFeature([], tf.float32),\n",
        "        \"width\": tf.io.FixedLenFeature([], tf.float32),\n",
        "        \"height\": tf.io.FixedLenFeature([], tf.float32),\n",
        "        \"phi\": tf.io.FixedLenFeature([], tf.float32),\n",
        "\n",
        "        \"category_id\": tf.io.FixedLenFeature([], tf.int64),\n",
        "        \"id\": tf.io.FixedLenFeature([], tf.int64),\n",
        "        \"image_id\": tf.io.FixedLenFeature([], tf.int64),\n",
        "        \"is_crowd\": tf.io.FixedLenFeature([], tf.int64),\n",
        "    }\n",
        "    example = tf.io.parse_single_example(example, feature_description)\n",
        "    example[\"image\"] = tf.io.decode_png(example[\"image\"], channels=3)\n",
        "    return example"
      ],
      "metadata": {
        "id": "siCNWk4HPv_q"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dict()\n",
        "for key in sorted(images, key=lambda x: x['id']):\n",
        "    dataset[key['id']] = dict()\n",
        "    file_name = key['file_name']\n",
        "    dataset[key['id']]['file_name'] = file_name"
      ],
      "metadata": {
        "id": "9nuR680MPzBF"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for annot in annotations:\n",
        "    if 'image_id' not in dataset[annot['image_id']]:\n",
        "        dataset[annot['image_id']]['image_id'] = annot['image_id']\n",
        "\n",
        "        dataset[annot['image_id']]['area'] = [annot['area']]\n",
        "\n",
        "        dataset[annot['image_id']]['row'] = [annot['bbox'][0]]\n",
        "        dataset[annot['image_id']]['col'] = [annot['bbox'][1]]\n",
        "        dataset[annot['image_id']]['width'] = [annot['bbox'][2]]\n",
        "        dataset[annot['image_id']]['height'] = [annot['bbox'][3]]\n",
        "        dataset[annot['image_id']]['phi'] = [annot['bbox'][4]]\n",
        "\n",
        "        dataset[annot['image_id']]['category_id'] = [annot['category_id']]\n",
        "        dataset[annot['image_id']]['id'] = [annot['id']]\n",
        "        dataset[annot['image_id']]['is_crowd'] = [annot['is_crowd']]      \n",
        "\n",
        "    else:\n",
        "        dataset[annot['image_id']]['area'].append(annot['area'])\n",
        "\n",
        "        dataset[annot['image_id']]['row'].append(annot['bbox'][0])\n",
        "        dataset[annot['image_id']]['col'].append(annot['bbox'][1])\n",
        "        dataset[annot['image_id']]['width'].append(annot['bbox'][2])\n",
        "        dataset[annot['image_id']]['height'].append(annot['bbox'][3])\n",
        "        dataset[annot['image_id']]['phi'].append(annot['bbox'][4])\n",
        "\n",
        "        dataset[annot['image_id']]['category_id'].append(annot['category_id'])\n",
        "        dataset[annot['image_id']]['id'].append(annot['id'])\n",
        "        dataset[annot['image_id']]['is_crowd'].append(annot['is_crowd'])\n"
      ],
      "metadata": {
        "id": "i0SSYunhP2Ha"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(tfrecords_dir):\n",
        "    os.makedirs(tfrecords_dir)  # creating TFRecords output folder\n",
        "for tfrec_num in range(num_tfrecords):\n",
        "    #samples = dataset[(tfrec_num * num_samples) : ((tfrec_num + 1) * num_samples)]\n",
        "    samples = list(dataset.values())\n",
        "\n",
        "    with tf.io.TFRecordWriter(\n",
        "        tfrecords_dir + \"/file_%.2i-%i.tfrec\" % (tfrec_num, len(samples))\n",
        "    ) as writer:\n",
        "        for sample in samples:\n",
        "            image_path = os.path.join(images_dir, sample['file_name'])\n",
        "            image = tf.io.decode_png(tf.io.read_file(image_path))\n",
        "            example = create_example(image, image_path, sample)\n",
        "            writer.write(example.SerializeToString())"
      ],
      "metadata": {
        "id": "DHxOFX03P2-P"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfrecord_filename = tfrecords_dir + \"/file_%.2i-%i.tfrec\" % (tfrec_num, len(samples))\n",
        "raw_data = tf.data.TFRecordDataset(tfrecord_filename)\n",
        "\n",
        "for raw_record in raw_data.take(1):\n",
        "  example = tf.train.Example()\n",
        "  example.ParseFromString(raw_record.numpy())\n",
        "  print(example)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InDAnXR4P4zZ",
        "outputId": "78d7a85b-57ea-4576-c06f-33731e41b830"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ]
    }
  ]
}