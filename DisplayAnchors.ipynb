{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7yb5zC1iHjj"
      },
      "source": [
        "# Displaying Rotated Anchor Boxes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MzNkG8IziHjm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "class AnchorBox:\n",
        "    \"\"\"Generates anchor boxes.\n",
        "\n",
        "    This class has operations to generate anchor boxes for feature maps at\n",
        "    strides `[8, 16, 32, 64, 128]`. Where each anchor each box is of the\n",
        "    format `[x, y, width, height, phi]`.\n",
        "\n",
        "    Attributes:\n",
        "      aspect_ratios: A list of float values representing the aspect ratios of\n",
        "        the anchor boxes at each location on the feature map\n",
        "      scales: A list of float values representing the scale of the anchor boxes\n",
        "        at each location on the feature map.\n",
        "      num_anchors: The number of anchor boxes at each location on feature map\n",
        "      areas: A list of float values representing the areas of the anchor\n",
        "        boxes for each feature map in the feature pyramid.\n",
        "      strides: A list of float value representing the strides for each feature\n",
        "        map in the feature pyramid.\n",
        "      angles: A list of int values representing angles.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        #self.aspect_ratios = [0.5, 1.0, 2.0]\n",
        "        self.aspect_ratios = [1.0]\n",
        "        self.scales = [2 ** x for x in [0, 1 / 3, 2 / 3]]\n",
        "\n",
        "        #adding in angle data\n",
        "        self.angles = [-90, -45]\n",
        "\n",
        "        self._num_anchors = len(self.aspect_ratios) * len(self.scales) #* len(self.angles)\n",
        "        self._strides = [2 ** i for i in range(3, 8)]\n",
        "        self._areas = [x ** 2 for x in [32.0, 64.0, 128.0, 256.0, 512.0]]\n",
        "        self._anchor_dims = self._compute_dims()\n",
        "\n",
        "    def _compute_dims(self):\n",
        "        \"\"\"Computes anchor box dimensions for all ratios and scales at all levels\n",
        "        of the feature pyramid.\n",
        "        \"\"\"\n",
        "        anchor_dims_all = []\n",
        "        for area in self._areas:\n",
        "            anchor_dims = []\n",
        "            for ratio in self.aspect_ratios:\n",
        "                anchor_height = tf.math.sqrt(area / ratio)\n",
        "                anchor_width = area / anchor_height\n",
        "                dims = tf.reshape(\n",
        "                    tf.stack([anchor_width, anchor_height], axis=-1), [1, 1, 2]\n",
        "                )\n",
        "                for scale in self.scales:\n",
        "                    anchor_dims.append(scale * dims)\n",
        "            anchor_dims_all.append(tf.stack(anchor_dims, axis=-2))\n",
        "        return anchor_dims_all\n",
        "\n",
        "    def _get_anchors(self, feature_height, feature_width, level):\n",
        "        \"\"\"Generates anchor boxes for a given feature map size and level\n",
        "\n",
        "        Arguments:\n",
        "          feature_height: An integer representing the height of the feature map.\n",
        "          feature_width: An integer representing the width of the feature map.\n",
        "          level: An integer representing the level of the feature map in the\n",
        "            feature pyramid.\n",
        "\n",
        "        Returns:\n",
        "          anchor boxes with the shape\n",
        "          `(feature_height * feature_width * num_anchors, 4)`\n",
        "        \"\"\"\n",
        "        rx = tf.range(feature_width, dtype=tf.float32) + 0.5\n",
        "        ry = tf.range(feature_height, dtype=tf.float32) + 0.5\n",
        "        centers = tf.stack(tf.meshgrid(rx, ry), axis=-1) * self._strides[level - 3]\n",
        "        centers = tf.expand_dims(centers, axis=-2)\n",
        "        centers = tf.tile(centers, [1, 1, self._num_anchors, 1])\n",
        "        dims = tf.tile(\n",
        "            self._anchor_dims[level - 3], [feature_height, feature_width, 1, 1]\n",
        "        )\n",
        "        anchors = tf.concat([centers, dims], axis=-1)\n",
        "        return tf.reshape(\n",
        "            anchors, [feature_height * feature_width * self._num_anchors, 4]\n",
        "        )\n",
        "\n",
        "    def get_anchors(self, image_height, image_width):\n",
        "        \"\"\"Generates anchor boxes for all the feature maps of the feature pyramid.\n",
        "\n",
        "        Arguments:\n",
        "          image_height: Height of the input image.\n",
        "          image_width: Width of the input image.\n",
        "\n",
        "        Returns:\n",
        "          anchor boxes for all the feature maps, stacked as a single tensor\n",
        "            with shape `(total_anchors, 4)`\n",
        "        \"\"\"\n",
        "        anchors = [\n",
        "            self._get_anchors(\n",
        "                tf.math.ceil(image_height / 2 ** i),\n",
        "                tf.math.ceil(image_width / 2 ** i),\n",
        "                i,\n",
        "            )\n",
        "            for i in range(3, 8)\n",
        "        ]\n",
        "        return tf.concat(anchors, axis=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def visualize_detections(\n",
        "    image, boxes, figsize=(7, 7), linewidth=1, color=[0, 0, 1]\n",
        "):\n",
        "    \"\"\"Visualize Detections\"\"\"\n",
        "    image = np.array(image, dtype=np.uint8)\n",
        "    plt.figure(figsize=figsize)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(image)\n",
        "    ax = plt.gca()\n",
        "    for box in boxes:\n",
        "        x1, y1, x2, y2 = box\n",
        "        w, h = x2 - x1, y2 - y1\n",
        "        patch = plt.Rectangle(\n",
        "            [x1, y1], w, h, fill=False, edgecolor=color, linewidth=linewidth\n",
        "        )\n",
        "        ax.add_patch(patch)\n",
        "    plt.show()\n",
        "    return ax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "boxes = AnchorBox()\n",
        "img = tf.zeros([100, 100, 3])\n",
        "\n",
        "anchors = boxes.get_anchors(100, 100)\n",
        "\n",
        "anchor_dims = boxes._compute_dims()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 504x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<AxesSubplot:>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "visualize_detections(img, anchors)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "retinanet",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "61c63460f299b72050a017299847de40e48391aa12573d6685850838867f4476"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 64-bit",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
